[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for de.org.dexterity.bookanything.backend:bookanything-monolith-backend-01:jar:1.0.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.apache.maven.plugins:maven-enforcer-plugin is missing. @ line 438, column 12
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] 
[INFO] --< de.org.dexterity.bookanything.backend:bookanything-monolith-backend-01 >--
[INFO] Building BookAnything-Monolith-Backend-01 1.0.0-SNAPSHOT
[INFO]   from pom.xml
[INFO] --------------------------------[ jar ]---------------------------------
[INFO] 
[INFO] --- clean:3.2.0:clean (default-clean) @ bookanything-monolith-backend-01 ---
[INFO] Deleting /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/target
[INFO] 
[INFO] --- resources:3.3.1:resources (default-resources) @ bookanything-monolith-backend-01 ---
[INFO] Copying 3 resources from src/main/resources to target/classes
[INFO] Copying 14 resources from src/main/resources to target/classes
[INFO] 
[INFO] --- compiler:3.14.0:compile (default-compile) @ bookanything-monolith-backend-01 ---
[INFO] Nothing to compile - all classes are up to date.
[INFO] 
[INFO] --- kotlin:2.1.21:compile (compile) @ bookanything-monolith-backend-01 ---
[INFO] Applied plugin: 'spring'
[INFO] Applied plugin: 'jpa'
[INFO] Applied plugin: 'all-open'
[WARNING] /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/src/main/kotlin/de/org/dexterity/bookanything/dom01geolocation/infrastructure/adapters/output/persistence/elasticsearch/adapters/LocalizablePlaceElasticSearchAdapter.kt: (56, 9) The corresponding parameter in the supertype 'LocalizablePlaceQueryRepositoryPort' is named 'localizacao'. This may cause problems when calling this function with named arguments.
[WARNING] /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/src/main/kotlin/de/org/dexterity/bookanything/dom01geolocation/infrastructure/adapters/output/persistence/elasticsearch/adapters/LocalizablePlaceElasticSearchAdapter.kt: (75, 49) The corresponding parameter in the supertype 'LocalizablePlaceQueryRepositoryPort' is named 'sourceCentroDistribuicaoList'. This may cause problems when calling this function with named arguments.
[WARNING] /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/src/main/kotlin/de/org/dexterity/bookanything/wire/security/SecurityConfig.kt: (29, 54) 'fun jwt(): OAuth2ResourceServerConfigurer.JwtConfigurer<HttpSecurity!>!' is deprecated. Deprecated in Java.
[INFO] 
[INFO] --- resources:3.3.1:testResources (default-testResources) @ bookanything-monolith-backend-01 ---
[INFO] Copying 2 resources from src/test/resources to target/test-classes
[INFO] 
[INFO] --- compiler:3.14.0:testCompile (default-testCompile) @ bookanything-monolith-backend-01 ---
[INFO] Recompiling the module because of changed dependency.
[INFO] 
[INFO] --- kotlin:2.1.21:test-compile (test-compile) @ bookanything-monolith-backend-01 ---
[INFO] Applied plugin: 'spring'
[INFO] Applied plugin: 'jpa'
[INFO] Applied plugin: 'all-open'
[WARNING] /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/src/test/kotlin/de/org/dexterity/bookanything/dom01geolocation/AbstractIntegrationTest.kt: (6, 8) 'class KafkaContainer : GenericContainer<KafkaContainer!>' is deprecated. Deprecated in Java.
[WARNING] /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/src/test/kotlin/de/org/dexterity/bookanything/dom01geolocation/AbstractIntegrationTest.kt: (30, 20) 'class KafkaContainer : GenericContainer<KafkaContainer!>' is deprecated. Deprecated in Java.
[WARNING] /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/src/test/kotlin/de/org/dexterity/bookanything/dom01geolocation/AbstractIntegrationTest.kt: (30, 37) 'constructor(p0: DockerImageName!): KafkaContainer' is deprecated. Deprecated in Java.
[INFO] 
[INFO] --- surefire:3.5.3:test (default-test) @ bookanything-monolith-backend-01 ---
[INFO] Using auto detected provider org.apache.maven.surefire.junitplatform.JUnitPlatformProvider
[INFO] 
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.GeoJsonUploadIntegrationTest
18:24:30.714 [main] INFO org.testcontainers.images.PullPolicy -- Image pull policy will be performed by: DefaultPullPolicy()
18:24:30.723 [main] INFO org.testcontainers.utility.ImageNameSubstitutor -- Image name substitution will be performed by: DefaultImageNameSubstitutor (composite of 'ConfigurationFileImageNameSubstitutor' and 'PrefixingImageNameSubstitutor')
18:24:30.773 [main] INFO org.testcontainers.DockerClientFactory -- Testcontainers version: 1.21.0
18:24:31.025 [main] INFO org.testcontainers.dockerclient.DockerClientProviderStrategy -- Loaded org.testcontainers.dockerclient.UnixSocketClientProviderStrategy from ~/.testcontainers.properties, will try it first
18:24:31.324 [main] INFO org.testcontainers.dockerclient.DockerClientProviderStrategy -- Found Docker environment with Environment variables, system properties and defaults. Resolved dockerHost=unix:///var/run/docker.sock
18:24:31.326 [main] INFO org.testcontainers.DockerClientFactory -- Docker host IP address is localhost
18:24:31.347 [main] INFO org.testcontainers.DockerClientFactory -- Connected to docker: 
  Server Version: 28.3.2
  API Version: 1.51
  Operating System: Linux Mint 22
  Total Memory: 64011 MB
18:24:31.394 [main] INFO tc.testcontainers/ryuk:0.11.0 -- Creating container for image: testcontainers/ryuk:0.11.0
18:24:31.572 [main] INFO tc.testcontainers/ryuk:0.11.0 -- Container testcontainers/ryuk:0.11.0 is starting: a4c718319339a5b39c53a1f01af7ed3e84ffb2c7ed9f325ceeff1fa5aaa63029
18:24:31.868 [main] INFO tc.testcontainers/ryuk:0.11.0 -- Container testcontainers/ryuk:0.11.0 started in PT0.474148275S
18:24:31.875 [main] INFO org.testcontainers.utility.RyukResourceReaper -- Ryuk started - will monitor and terminate Testcontainers containers on JVM exit
18:24:31.875 [main] INFO org.testcontainers.DockerClientFactory -- Checking the system...
18:24:31.875 [main] INFO org.testcontainers.DockerClientFactory -- ✔︎ Docker server version should be at least 1.6.0
18:24:31.878 [main] INFO tc.elasticsearch:8.14.0 -- Creating container for image: elasticsearch:8.14.0
18:24:31.983 [main] INFO tc.elasticsearch:8.14.0 -- Container elasticsearch:8.14.0 is starting: dd021ca32cab54038fae7162cfcb2eeb434fd6751823c7fa67b5acbaa2cdc7e0
18:24:58.189 [main] INFO tc.elasticsearch:8.14.0 -- Container elasticsearch:8.14.0 started in PT26.310999077S
18:24:58.190 [main] INFO tc.confluentinc/cp-kafka:7.6.0 -- Creating container for image: confluentinc/cp-kafka:7.6.0
18:24:58.302 [main] INFO tc.confluentinc/cp-kafka:7.6.0 -- Container confluentinc/cp-kafka:7.6.0 is starting: 3b3c29e6c8616dd94215432a209ec8f62a68c16950f45b3a35e493d8f996a7ed
18:25:05.159 [main] INFO tc.confluentinc/cp-kafka:7.6.0 -- Container confluentinc/cp-kafka:7.6.0 started in PT6.969007779S
18:25:05.169 [main] INFO tc.keycloak/keycloak:26.3.1 -- Creating container for image: keycloak/keycloak:26.3.1
18:25:05.331 [main] INFO tc.keycloak/keycloak:26.3.1 -- Container keycloak/keycloak:26.3.1 is starting: 271e43526b848a7bd896339bc1540155149a94b079ea09ebada092f47c80ee7b
18:25:05.651 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
18:25:05.663 [main] INFO org.testcontainers.containers.wait.strategy.HttpWaitStrategy -- /condescending_brahmagupta: Waiting for 120 seconds for URL: http://localhost:34690/health/started (where port 34690 maps to container port 9000)
18:25:06.738 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
18:25:17.119 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:17,117 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 9550ms
18:25:18.143 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: Running the server in development mode. DO NOT use this configuration in production.
18:25:23.316 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:23,315 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
18:25:27.216 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:27,215 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
18:25:27.487 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:27,486 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
18:25:27.916 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:27,915 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_324700, Site name: null
18:25:28.146 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:28,145 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
18:25:28.156 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:28,155 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
18:25:29.738 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:29,738 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
18:25:32.320 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:32,319 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
18:25:32.327 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:32,326 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
18:25:32.467 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:32,466 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
18:25:32.688 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:32,686 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 15.382s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
18:25:32.688 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:32,687 INFO  [io.quarkus] (main) Profile dev activated. 
18:25:32.688 [docker-java-stream--193224658] INFO tc.keycloak/keycloak:26.3.1 -- STDOUT: 2025-07-15 16:25:32,687 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
18:25:32.871 [main] INFO tc.keycloak/keycloak:26.3.1 -- Container keycloak/keycloak:26.3.1 started in PT27.702581705S
18:25:32.873 [main] INFO tc.postgis/postgis:16-3.4 -- Creating container for image: postgis/postgis:16-3.4
18:25:32.944 [main] INFO tc.postgis/postgis:16-3.4 -- Container postgis/postgis:16-3.4 is starting: 658b77c00ed62bf01035e329c8e467333dab81728b013b784154457d8675b899
18:25:35.644 [main] INFO tc.postgis/postgis:16-3.4 -- Container postgis/postgis:16-3.4 started in PT2.771515498S
18:25:35.646 [main] INFO tc.postgis/postgis:16-3.4 -- Container is started (JDBC URL: jdbc:postgresql://localhost:34691/DBBookAnythingPlatform?loggerLevel=OFF)
18:25:35.773 [main] INFO org.springframework.test.context.support.AnnotationConfigContextLoaderUtils -- Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.GeoJsonUploadIntegrationTest]: GeoJsonUploadIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
18:25:35.953 [main] INFO org.springframework.boot.test.context.SpringBootTestContextBootstrapper -- Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.GeoJsonUploadIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:25:36.546 INFO  [background-preinit] o.h.validator.internal.util.Version - HV000001: Hibernate Validator 8.0.2.Final
2025-07-15 18:25:36.599 INFO  [main] d.o.d.b.d.GeoJsonUploadIntegrationTest - Starting GeoJsonUploadIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:25:36.600 INFO  [main] d.o.d.b.d.GeoJsonUploadIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:25:38.503 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:25:38.508 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:25:38.605 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.610 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.612 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.613 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.614 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.615 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.615 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.616 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:25:38.650 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 123 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:25:38.667 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:25:38.670 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:25:38.703 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:25:38.739 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 57 ms. Found 8 JPA repository interfaces.
2025-07-15 18:25:39.747 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:25:39.988 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@13e5b262
2025-07-15 18:25:39.990 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:25:40.232 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:25:40.691 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:25:40.726 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:25:40.748 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:25:40.804 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:25:40.807 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:25:40.813 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:25:40.813 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:25:40.813 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:25:40.813 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:25:40.813 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:25:40.814 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:25:40.814 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:25:40.816 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:25:41.696 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:25:41.840 INFO  [task-1] org.hibernate.Version - HHH000412: Hibernate ORM core version 6.6.18.Final
2025-07-15 18:25:41.873 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:25:41.964 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:25:42.361 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:25:42.390 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:25:42.704 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:25:42.743 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:25:43.543 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:25:44.644 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:25:44.695 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@173ae49c] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:25:44.773 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:25:44.773 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:25:44.782 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:25:45.409 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:25:46.246 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:25:46.247 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:25:46.249 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 2 ms
2025-07-15 18:25:46.420 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34687]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:25:46.479 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:25:46.665 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:25:46.665 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:25:46.665 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596746662
2025-07-15 18:25:46.680 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:25:46.696 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34687]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:25:46.697 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:25:46.705 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:25:46.705 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:25:46.706 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596746705
2025-07-15 18:25:46.711 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:25:46.714 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34687]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:25:46.714 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:25:46.720 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:25:46.721 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:25:46.721 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596746720
2025-07-15 18:25:46.725 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:25:46.727 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34687]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:25:46.728 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:25:46.732 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:25:46.732 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:25:46.732 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596746732
2025-07-15 18:25:46.736 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:25:46.739 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:25:47.419 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.419 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.419 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.419 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Cluster ID: c3R0lgLOQlOVTPxLo2JCmQ
2025-07-15 18:25:47.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Cluster ID: c3R0lgLOQlOVTPxLo2JCmQ
2025-07-15 18:25:47.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Cluster ID: c3R0lgLOQlOVTPxLo2JCmQ
2025-07-15 18:25:47.423 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Cluster ID: c3R0lgLOQlOVTPxLo2JCmQ
2025-07-15 18:25:47.537 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.560 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.560 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.561 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.765 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.799 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.799 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.805 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:25:47.846 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:25:47.877 INFO  [main] d.o.d.b.d.GeoJsonUploadIntegrationTest - Started GeoJsonUploadIntegrationTest in 11.71 seconds (process running for 78.291)
Mockito is currently self-attaching to enable the inline-mock-maker. This will no longer work in future releases of the JDK. Please add Mockito as an agent to your build as described in Mockito's documentation: https://javadoc.io/doc/org.mockito/mockito-core/latest/org.mockito/org/mockito/Mockito.html#0.3
2025-07-15 18:25:48.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34687 (id: 2147483646 rack: null)
2025-07-15 18:25:48.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Discovered group coordinator localhost:34687 (id: 2147483646 rack: null)
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
2025-07-15 18:25:48.242 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:25:48.242 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] (Re-)joining group
WARNING: A Java agent has been loaded dynamically (/home/andre.nascimento/DevEnvALNS/infra/fast-shared-m2repo/net/bytebuddy/byte-buddy-agent/1.17.6/byte-buddy-agent-1.17.6.jar)
WARNING: If a serviceability tool is in use, please run with -XX:+EnableDynamicAgentLoading to hide this warning
WARNING: If a serviceability tool is not in use, please run with -Djdk.instrument.traceUsage for more information
WARNING: Dynamic loading of agents will be disallowed by default in a future release
2025-07-15 18:25:48.283 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34687 (id: 2147483646 rack: null)
2025-07-15 18:25:48.283 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34687 (id: 2147483646 rack: null)
2025-07-15 18:25:48.284 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:25:48.284 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:25:48.295 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-4-3b16063a-27fd-4dfc-a032-437a89cae543
2025-07-15 18:25:48.295 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-2-3b317837-a923-4cdd-88e7-5ace7e53ddeb
2025-07-15 18:25:48.297 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:25:48.297 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:25:48.302 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-3-462c65d9-4590-4136-9d75-1695c3f83a5e
2025-07-15 18:25:48.302 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-1-ba15294d-9faa-446e-987e-7f532829b943
2025-07-15 18:25:48.303 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:25:48.303 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:25:48.331 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-3-462c65d9-4590-4136-9d75-1695c3f83a5e', protocol='range'}
2025-07-15 18:25:48.333 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-4-3b16063a-27fd-4dfc-a032-437a89cae543', protocol='range'}
2025-07-15 18:25:48.334 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-1-ba15294d-9faa-446e-987e-7f532829b943', protocol='range'}
2025-07-15 18:25:48.336 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-2-3b317837-a923-4cdd-88e7-5ace7e53ddeb', protocol='range'}
2025-07-15 18:25:48.341 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-4-3b16063a-27fd-4dfc-a032-437a89cae543=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:25:48.341 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-3-462c65d9-4590-4136-9d75-1695c3f83a5e=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:25:48.341 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-2-3b317837-a923-4cdd-88e7-5ace7e53ddeb=Assignment(partitions=[geojson-upload-topic-0])}
2025-07-15 18:25:48.341 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-1-ba15294d-9faa-446e-987e-7f532829b943=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
2025-07-15 18:25:48.442 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-4-3b16063a-27fd-4dfc-a032-437a89cae543', protocol='range'}
2025-07-15 18:25:48.442 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-3-462c65d9-4590-4136-9d75-1695c3f83a5e', protocol='range'}
2025-07-15 18:25:48.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-1-ba15294d-9faa-446e-987e-7f532829b943', protocol='range'}
2025-07-15 18:25:48.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-2-3b317837-a923-4cdd-88e7-5ace7e53ddeb', protocol='range'}
2025-07-15 18:25:48.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:25:48.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:25:48.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:25:48.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:25:48.447 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:25:48.447 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:25:48.447 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:25:48.447 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:25:48.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:25:48.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:25:48.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:25:48.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:25:48.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:25:48.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:25:48.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:25:48.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:25:48.516 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34687 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:25:48.516 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34687 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:25:48.516 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34687 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:25:48.516 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34687 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:25:48.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:25:48.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:25:48.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:25:48.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:25:49.073 INFO  [main] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:34687]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = BookAnythingBackendApplication-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 52428800
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-07-15 18:25:49.074 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:25:49.086 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Instantiated an idempotent producer.
2025-07-15 18:25:49.108 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:25:49.109 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:25:49.109 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596749108
2025-07-15 18:25:49.116 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=BookAnythingBackendApplication-producer-1] Cluster ID: c3R0lgLOQlOVTPxLo2JCmQ
2025-07-15 18:25:49.231 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=BookAnythingBackendApplication-producer-1] ProducerId set to 0 with epoch 0
2025-07-15 18:25:49.448 INFO  [main] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - The uploaded file was successfully validated and queued to be processed ASAP. You'll be notified when it gets done.
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
2025-07-15 18:25:50.297 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> SUCCESS :: O seguinte Centro de Distribuição foi cadastrado com sucesso: North Carolina - Cary - TOWN OF CARY / BOND PARK - Coordenadas: POINT (-78.825554 35.781303)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:25:50.309 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=197d5db8-fe74-492e-bae5-5de9122d89b2, nome=North Carolina - Cary - TOWN OF CARY / BOND PARK
Documents found in ElasticSearch: 
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:25:50.331 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> SUCCESS :: O seguinte Centro de Distribuição foi cadastrado com sucesso: North Carolina - Cary - TOWN OF CARY / P2_DTCARYDECKE1 - Coordenadas: POINT (-78.779411 35.785446)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:25:50.351 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> SUCCESS :: O seguinte Centro de Distribuição foi cadastrado com sucesso: North Carolina - Cary - TOWN OF CARY / P2_DTCARYDEKCE2 - Coordenadas: POINT (-78.779701 35.785385)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:25:50.361 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> FAIL :: Verificação de Duplicação de Centro de Distribuição: Centro de Distribuição com o nome 'North Carolina - Cary - TOWN OF CARY / BOND PARK' já existe.
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:25:50.386 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> SUCCESS :: O seguinte Centro de Distribuição foi cadastrado com sucesso: North Carolina - Cary - TOWN OF CARY / TOWNHALLEAST - Coordenadas: POINT (-78.778816 35.789215)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:25:50.394 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> FAIL :: Verificação de Duplicação de Centro de Distribuição: Centro de Distribuição com o nome 'North Carolina - Cary - TOWN OF CARY / P2_DTCARYDECKE1' já existe.
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:25:50.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> SUCCESS :: O seguinte Centro de Distribuição foi cadastrado com sucesso: North Carolina - Cary - TOWN OF CARY / P3_DTCARYDECKW - Coordenadas: POINT (-78.779282 35.785282)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:25:50.428 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] d.o.d.b.d.a.u.GeoJsonFileManagerUseCase - ==> FAIL :: Verificação de Duplicação de Centro de Distribuição: Centro de Distribuição com o nome 'North Carolina - Cary - TOWN OF CARY / P2_DTCARYDEKCE2' já existe.
Documents found in ElasticSearch: 
2025-07-15 18:25:50.675 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=197d5db8-fe74-492e-bae5-5de9122d89b2, nome=North Carolina - Cary - TOWN OF CARY / BOND PARK
2025-07-15 18:25:50.686 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=841a1977-742d-4251-8fc7-57dc82f39d57, nome=North Carolina - Cary - TOWN OF CARY / P2_DTCARYDECKE1
2025-07-15 18:25:50.755 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=841a1977-742d-4251-8fc7-57dc82f39d57, nome=North Carolina - Cary - TOWN OF CARY / P2_DTCARYDECKE1
2025-07-15 18:25:50.760 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=a888b2f0-12db-4e95-b1e7-0e58a3afac39, nome=North Carolina - Cary - TOWN OF CARY / P2_DTCARYDEKCE2
Documents found in ElasticSearch: 197d5db8-fe74-492e-bae5-5de9122d89b2
2025-07-15 18:25:50.824 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=a888b2f0-12db-4e95-b1e7-0e58a3afac39, nome=North Carolina - Cary - TOWN OF CARY / P2_DTCARYDEKCE2
2025-07-15 18:25:50.824 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=4b268024-bfb2-4dda-a3cc-1a1b4a8fcd00, nome=North Carolina - Cary - TOWN OF CARY / TOWNHALLEAST
2025-07-15 18:25:50.916 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=4b268024-bfb2-4dda-a3cc-1a1b4a8fcd00, nome=North Carolina - Cary - TOWN OF CARY / TOWNHALLEAST
2025-07-15 18:25:50.918 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=6ed2d13c-5cb9-4839-b351-624b126eea21, nome=North Carolina - Cary - TOWN OF CARY / P3_DTCARYDECKW
Documents found in ElasticSearch: 197d5db8-fe74-492e-bae5-5de9122d89b2, 841a1977-742d-4251-8fc7-57dc82f39d57, a888b2f0-12db-4e95-b1e7-0e58a3afac39, 4b268024-bfb2-4dda-a3cc-1a1b4a8fcd00
2025-07-15 18:25:51.042 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=6ed2d13c-5cb9-4839-b351-624b126eea21, nome=North Carolina - Cary - TOWN OF CARY / P3_DTCARYDECKW
2025-07-15 18:25:51.237 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:25:51.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:25:51.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:25:51.237 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:25:51.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:25:51.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:25:51.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:25:51.238 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:25:51.239 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-4-3b16063a-27fd-4dfc-a032-437a89cae543 sending LeaveGroup request to coordinator localhost:34687 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:25:51.239 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-1-ba15294d-9faa-446e-987e-7f532829b943 sending LeaveGroup request to coordinator localhost:34687 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:25:51.239 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-3-462c65d9-4590-4136-9d75-1695c3f83a5e sending LeaveGroup request to coordinator localhost:34687 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:25:51.239 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Member consumer-geojson-processor-2-3b317837-a923-4cdd-88e7-5ace7e53ddeb sending LeaveGroup request to coordinator localhost:34687 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:25:51.240 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.240 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.240 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.240 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.240 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.240 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.241 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:25:51.241 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:25:51.241 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.241 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.241 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:25:51.241 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:25:51.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.244 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-4, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.244 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-2, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.244 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-1, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.244 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-3, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:25:51.268 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:25:51.269 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:25:51.269 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:25:51.270 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:25:51.284 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-3 unregistered
2025-07-15 18:25:51.286 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:25:51.467 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:25:51.467 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:25:51.467 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:25:51.467 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:25:51.470 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-2 unregistered
2025-07-15 18:25:51.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:25:51.709 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:25:51.709 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:25:51.710 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:25:51.710 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:25:51.710 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:25:51.710 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:25:51.710 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:25:51.710 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:25:51.718 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-1 unregistered
2025-07-15 18:25:51.718 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:25:51.718 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-4 unregistered
2025-07-15 18:25:51.719 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:25:51.719 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-07-15 18:25:51.725 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:25:51.725 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:25:51.725 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:25:51.725 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:25:51.726 INFO  [main] o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for BookAnythingBackendApplication-producer-1 unregistered
2025-07-15 18:25:51.744 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:25:51.747 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:25:51.750 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 82.59 s -- in de.org.dexterity.bookanything.dom01geolocation.GeoJsonUploadIntegrationTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceCreationIntegrationTest
2025-07-15 18:25:53.256 INFO  [main] tc.elasticsearch:8.14.0 - Creating container for image: elasticsearch:8.14.0
2025-07-15 18:25:53.350 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 is starting: 283195bff29fe38ec5469d3773b258cbface8f6c9fdbe0c59fb56c1815b4a349
2025-07-15 18:26:15.259 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 started in PT22.003088448S
2025-07-15 18:26:15.260 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Creating container for image: confluentinc/cp-kafka:7.6.0
2025-07-15 18:26:15.328 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 is starting: 8ffb839d482de6fb82ab5d1f620d389773e4ccfbb7aaf001059a60598fb7dfd7
2025-07-15 18:26:22.600 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 started in PT7.340758655S
2025-07-15 18:26:22.602 INFO  [main] tc.keycloak/keycloak:26.3.1 - Creating container for image: keycloak/keycloak:26.3.1
2025-07-15 18:26:22.701 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 is starting: 69af1f9a5adf92783fb4e369c25a24dcd317f809b1b98ca221806a678f18381f
2025-07-15 18:26:22.970 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
2025-07-15 18:26:22.977 INFO  [main] o.t.c.wait.strategy.HttpWaitStrategy - /laughing_carver: Waiting for 120 seconds for URL: http://localhost:34700/health/started (where port 34700 maps to container port 9000)
2025-07-15 18:26:23.928 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
2025-07-15 18:26:34.876 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:34,874 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 9925ms
2025-07-15 18:26:36.152 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: Running the server in development mode. DO NOT use this configuration in production.
2025-07-15 18:26:41.691 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:41,690 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
2025-07-15 18:26:45.432 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:45,431 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
2025-07-15 18:26:45.689 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:45,688 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
2025-07-15 18:26:46.110 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:46,109 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_447650, Site name: null
2025-07-15 18:26:46.337 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:46,337 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
2025-07-15 18:26:46.347 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:46,346 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
2025-07-15 18:26:48.265 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:48,264 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
2025-07-15 18:26:51.458 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:51,457 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
2025-07-15 18:26:51.467 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:51,466 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
2025-07-15 18:26:51.652 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:51,651 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
2025-07-15 18:26:51.896 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:51,895 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 16.851s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
2025-07-15 18:26:51.897 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:51,896 INFO  [io.quarkus] (main) Profile dev activated. 
2025-07-15 18:26:51.897 INFO  [docker-java-stream-1448613956] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:26:51,896 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
2025-07-15 18:26:52.184 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 started in PT29.582308758S
2025-07-15 18:26:52.184 INFO  [main] tc.postgis/postgis:16-3.4 - Creating container for image: postgis/postgis:16-3.4
2025-07-15 18:26:52.250 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 is starting: 9dd6a0112c593dc37acc9f8739a386f7ead88e76ee7cf166376ca200e9fdd336
2025-07-15 18:26:54.904 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 started in PT2.719469629S
2025-07-15 18:26:54.904 INFO  [main] tc.postgis/postgis:16-3.4 - Container is started (JDBC URL: jdbc:postgresql://localhost:34701/DBBookAnythingPlatform?loggerLevel=OFF)
2025-07-15 18:26:54.908 INFO  [main] o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceCreationIntegrationTest]: LocalizablePlaceCreationIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-07-15 18:26:54.919 INFO  [main] o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceCreationIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:26:54.969 INFO  [main] d.o.d.b.d.LocalizablePlaceCreationIntegrationTest - Starting LocalizablePlaceCreationIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:26:54.969 INFO  [main] d.o.d.b.d.LocalizablePlaceCreationIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:26:55.395 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:26:55.395 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:26:55.406 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.406 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.406 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.407 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.407 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.407 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.407 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.407 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:55.412 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 15 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:26:55.416 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:26:55.416 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:26:55.438 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:26:55.451 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 19 ms. Found 8 JPA repository interfaces.
2025-07-15 18:26:55.585 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:26:55.637 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@16e557d4
2025-07-15 18:26:55.637 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:26:55.657 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:26:55.717 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:26:55.725 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:26:55.737 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:26:55.766 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:26:55.768 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:26:55.769 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:26:55.770 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:26:55.770 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:26:55.770 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:26:55.770 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:26:55.770 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:26:55.770 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:26:55.770 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:26:55.815 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:26:55.821 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:26:55.823 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:26:55.835 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:26:55.835 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:26:55.841 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:26:55.843 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:26:55.941 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:26:56.005 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:26:56.006 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@a3d872a] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:26:56.052 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:26:56.052 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:26:56.059 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:26:56.938 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:26:57.097 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:26:57.098 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:26:57.099 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 1 ms
2025-07-15 18:26:57.136 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:57.137 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:57.142 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:57.142 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:57.142 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596817142
2025-07-15 18:26:57.145 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:26:57.149 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:57.150 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:57.157 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:57.157 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:57.157 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596817157
2025-07-15 18:26:57.162 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:26:57.165 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:57.166 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:57.170 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:57.171 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:57.171 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596817170
2025-07-15 18:26:57.175 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:26:57.177 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:57.177 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:57.181 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:57.181 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:57.181 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596817181
2025-07-15 18:26:57.186 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:26:57.188 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:26:57.263 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.263 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.263 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:57.263 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:57.263 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.264 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:57.264 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.265 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:57.331 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:26:57.338 INFO  [main] d.o.d.b.d.LocalizablePlaceCreationIntegrationTest - Started LocalizablePlaceCreationIntegrationTest in 2.413 seconds (process running for 147.753)
2025-07-15 18:26:57.345 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:57.345 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:57.350 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:57.351 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:57.351 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596817350
2025-07-15 18:26:57.355 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-test-group-9, groupId=test-group] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:26:57.374 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-test-group-9, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.374 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-group-9, groupId=test-group] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:57.392 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:26:57.404 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.404 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:26:57.421 INFO  [main] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = BookAnythingBackendApplication-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 52428800
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-07-15 18:26:57.422 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:57.424 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Instantiated an idempotent producer.
2025-07-15 18:26:57.430 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.431 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:57.432 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:57.432 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596817431
2025-07-15 18:26:57.458 WARN  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.apache.kafka.clients.NetworkClient - [Producer clientId=BookAnythingBackendApplication-producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.459 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=BookAnythingBackendApplication-producer-1] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:57.500 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-test-group-9, groupId=test-group] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.577 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=BookAnythingBackendApplication-producer-1] ProducerId set to 0 with epoch 0
2025-07-15 18:26:57.583 WARN  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.apache.kafka.clients.NetworkClient - [Producer clientId=BookAnythingBackendApplication-producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 8 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:26:57.631 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:57.633 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:26:57.659 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-8-72a814e3-9485-44f3-9212-b08e38fecab1
2025-07-15 18:26:57.660 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:26:57.674 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:57.675 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:26:57.687 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-7-79310f84-0ec0-4c72-b413-ba340dc34700
2025-07-15 18:26:57.687 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-8-72a814e3-9485-44f3-9212-b08e38fecab1', protocol='range'}
2025-07-15 18:26:57.687 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:26:57.688 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-8-72a814e3-9485-44f3-9212-b08e38fecab1=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:26:57.694 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-7-79310f84-0ec0-4c72-b413-ba340dc34700', protocol='range'}
2025-07-15 18:26:57.694 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-7-79310f84-0ec0-4c72-b413-ba340dc34700=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:26:57.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:57.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] (Re-)joining group
2025-07-15 18:26:57.703 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-9-39c903eb-beba-48b6-ae2a-0d3fcdfcfe67
2025-07-15 18:26:57.703 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] (Re-)joining group
2025-07-15 18:26:57.707 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-test-group-9-39c903eb-beba-48b6-ae2a-0d3fcdfcfe67', protocol='range'}
2025-07-15 18:26:57.708 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Finished assignment for group at generation 1: {consumer-test-group-9-39c903eb-beba-48b6-ae2a-0d3fcdfcfe67=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:26:57.751 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-8-72a814e3-9485-44f3-9212-b08e38fecab1', protocol='range'}
2025-07-15 18:26:57.751 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-test-group-9-39c903eb-beba-48b6-ae2a-0d3fcdfcfe67', protocol='range'}
2025-07-15 18:26:57.751 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-7-79310f84-0ec0-4c72-b413-ba340dc34700', protocol='range'}
2025-07-15 18:26:57.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:26:57.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:26:57.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:26:57.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:26:57.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-test-group-9, groupId=test-group] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:26:57.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:26:57.766 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:26:57.766 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:26:57.766 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:26:57.768 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:26:57.768 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:26:57.768 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:26:57.778 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-test-group-9, groupId=test-group] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:26:57.778 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:26:57.778 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:26:57.802 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:26:57.802 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer - test-group: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:26:57.802 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0
2025-07-15 18:26:57.904 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=1a5c58d5-0667-427d-8d4c-00b651cc47c1, nome=CD Teste
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
2025-07-15 18:26:57.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-test-group-9, groupId=test-group] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:26:57.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:26:57.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer - test-group: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:26:57.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:26:57.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Member consumer-test-group-9-39c903eb-beba-48b6-ae2a-0d3fcdfcfe67 sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:26:57.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-8-72a814e3-9485-44f3-9212-b08e38fecab1 sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-test-group-9, groupId=test-group] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:57.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-9, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.022 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:26:58.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-6, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.024 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:26:58.024 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:26:58.024 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:26:58.025 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:26:58.028 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-6 unregistered
2025-07-15 18:26:58.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:26:58.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:26:58.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-5, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.030 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:26:58.031 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:26:58.031 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:26:58.031 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:26:58.034 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-5 unregistered
2025-07-15 18:26:58.036 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:26:58.282 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=1a5c58d5-0667-427d-8d4c-00b651cc47c1, nome=CD Teste
2025-07-15 18:26:58.292 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:26:58.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:26:58.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-7-79310f84-0ec0-4c72-b413-ba340dc34700 sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:26:58.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:26:58.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-7, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:26:58.338 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-8, groupId=elasticsearch-deleter] Node 1 sent an invalid full fetch response with extraIds=(brmeU2eAQ6m0Scsq0SK1nQ), response=()
2025-07-15 18:26:58.343 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:26:58.343 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:26:58.343 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:26:58.343 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:26:58.348 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-8 unregistered
2025-07-15 18:26:58.348 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:26:58.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:26:58.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:26:58.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:26:58.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:26:58.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:26:58.423 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:26:58.423 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:26:58.423 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:26:58.429 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-7 unregistered
2025-07-15 18:26:58.429 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-group-9 unregistered
2025-07-15 18:26:58.429 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:26:58.429 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer - test-group: Consumer stopped
2025-07-15 18:26:58.430 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-07-15 18:26:58.435 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:26:58.435 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:26:58.435 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:26:58.436 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:26:58.436 INFO  [main] o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for BookAnythingBackendApplication-producer-1 unregistered
2025-07-15 18:26:58.448 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:26:58.450 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:26:58.454 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:26:58.514 INFO  [main] d.o.d.b.d.LocalizablePlaceCreationIntegrationTest - Starting LocalizablePlaceCreationIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:26:58.514 INFO  [main] d.o.d.b.d.LocalizablePlaceCreationIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:26:58.907 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:26:58.908 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:26:58.916 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.916 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.916 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.917 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.917 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.917 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.917 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.917 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:26:58.922 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 12 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:26:58.927 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:26:58.928 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:26:58.936 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:26:58.945 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 15 ms. Found 8 JPA repository interfaces.
2025-07-15 18:26:59.053 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:26:59.068 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@6603aeb8
2025-07-15 18:26:59.068 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:26:59.075 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:26:59.143 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:26:59.157 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:26:59.157 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:26:59.157 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:26:59.201 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:26:59.205 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:26:59.206 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:26:59.210 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:26:59.210 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:26:59.215 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:26:59.217 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:26:59.275 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:26:59.321 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:26:59.328 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@3b0510e1] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
2025-07-15 18:26:59.600 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:26:59.673 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:26:59.874 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:26:59.875 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:26:59.876 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 1 ms
2025-07-15 18:26:59.897 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:59.897 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:59.900 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:59.900 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:59.900 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596819900
2025-07-15 18:26:59.903 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:26:59.905 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:59.906 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:59.910 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:59.910 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:59.910 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596819910
2025-07-15 18:26:59.913 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:26:59.916 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:59.917 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:59.917 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:59.917 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:59.917 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:26:59.921 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:59.921 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:59.922 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:59.922 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596819921
2025-07-15 18:26:59.923 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-10-5344cdb7-5857-49d3-8e12-b965655fbd29
2025-07-15 18:26:59.923 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:59.923 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:26:59.925 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:26:59.926 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:26:59.931 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:26:59.932 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-10-5344cdb7-5857-49d3-8e12-b965655fbd29', protocol='range'}
2025-07-15 18:26:59.932 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:26:59.933 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-10-5344cdb7-5857-49d3-8e12-b965655fbd29=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
2025-07-15 18:26:59.937 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-11-83f152a2-5f04-4a08-a40a-cc8cc11367ab
2025-07-15 18:26:59.937 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:26:59.937 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:26:59.938 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596819937
2025-07-15 18:26:59.938 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:26:59.940 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:26:59.940 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-10-5344cdb7-5857-49d3-8e12-b965655fbd29', protocol='range'}
2025-07-15 18:26:59.941 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:26:59.941 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:26:59.942 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:26:59.942 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:59.943 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-11-83f152a2-5f04-4a08-a40a-cc8cc11367ab', protocol='range'}
2025-07-15 18:26:59.943 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:59.944 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-11-83f152a2-5f04-4a08-a40a-cc8cc11367ab=Assignment(partitions=[geojson-upload-topic-0])}
2025-07-15 18:26:59.945 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:26:59.945 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:26:59.948 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:26:59.954 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-11-83f152a2-5f04-4a08-a40a-cc8cc11367ab', protocol='range'}
2025-07-15 18:26:59.955 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:26:59.955 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:26:59.956 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:26:59.956 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:26:59.959 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:26:59.959 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-12-b0d93c88-d6bf-46ce-a255-292e3b4a5b18
2025-07-15 18:26:59.960 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:26:59.961 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:26:59.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:26:59.965 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:26:59.966 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=3, memberId='consumer-elasticsearch-indexer-12-b0d93c88-d6bf-46ce-a255-292e3b4a5b18', protocol='range'}
2025-07-15 18:26:59.969 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Finished assignment for group at generation 3: {consumer-elasticsearch-indexer-12-b0d93c88-d6bf-46ce-a255-292e3b4a5b18=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:26:59.970 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-13-6f40acd3-f02f-49ac-a6fc-55f6ca197aee
2025-07-15 18:26:59.970 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:26:59.971 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:26:59.976 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=3, memberId='consumer-elasticsearch-deleter-13-6f40acd3-f02f-49ac-a6fc-55f6ca197aee', protocol='range'}
2025-07-15 18:26:59.977 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:26:59.977 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=3, memberId='consumer-elasticsearch-indexer-12-b0d93c88-d6bf-46ce-a255-292e3b4a5b18', protocol='range'}
2025-07-15 18:26:59.977 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Finished assignment for group at generation 3: {consumer-elasticsearch-deleter-13-6f40acd3-f02f-49ac-a6fc-55f6ca197aee=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:26:59.978 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:26:59.978 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:26:59.986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=3, memberId='consumer-elasticsearch-deleter-13-6f40acd3-f02f-49ac-a6fc-55f6ca197aee', protocol='range'}
2025-07-15 18:26:59.987 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:26:59.988 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:26:59.988 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:26:59.988 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition localizable-place-created-topic-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:26:59.989 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:26:59.993 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition localizable-place-deleted-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:26:59.994 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:27:00.078 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:27:00.083 INFO  [main] d.o.d.b.d.LocalizablePlaceCreationIntegrationTest - Started LocalizablePlaceCreationIntegrationTest in 1.612 seconds (process running for 150.497)
2025-07-15 18:27:00.090 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-test-group-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-group
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:27:00.090 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:27:00.094 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:27:00.094 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:27:00.094 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596820094
2025-07-15 18:27:00.096 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-test-group-14, groupId=test-group] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:27:00.108 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-group-14, groupId=test-group] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:27:00.109 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Discovered group coordinator localhost:34697 (id: 2147483646 rack: null)
2025-07-15 18:27:00.109 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] (Re-)joining group
2025-07-15 18:27:00.114 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Request joining group due to: need to re-join with the given member-id: consumer-test-group-14-005036a1-1001-4c7d-9adb-4c0d3ff9162a
2025-07-15 18:27:00.114 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] (Re-)joining group
2025-07-15 18:27:00.118 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Successfully joined group with generation Generation{generationId=3, memberId='consumer-test-group-14-005036a1-1001-4c7d-9adb-4c0d3ff9162a', protocol='range'}
2025-07-15 18:27:00.119 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Finished assignment for group at generation 3: {consumer-test-group-14-005036a1-1001-4c7d-9adb-4c0d3ff9162a=Assignment(partitions=[localizable-place-created-topic-0])}
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:27:00.126 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Successfully synced group in generation Generation{generationId=3, memberId='consumer-test-group-14-005036a1-1001-4c7d-9adb-4c0d3ff9162a', protocol='range'}
2025-07-15 18:27:00.127 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:27:00.127 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-test-group-14, groupId=test-group] Adding newly assigned partitions: localizable-place-created-topic-0
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:27:00.131 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition localizable-place-created-topic-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34697 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:27:00.132 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer - test-group: partitions assigned: [localizable-place-created-topic-0]
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:27:00.149 INFO  [main] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:34697]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = BookAnythingBackendApplication-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 52428800
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-07-15 18:27:00.150 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:27:00.152 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Instantiated an idempotent producer.
2025-07-15 18:27:00.157 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:27:00.157 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:27:00.157 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596820156
2025-07-15 18:27:00.164 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=BookAnythingBackendApplication-producer-1] Cluster ID: IHyjX_8pTFumBqTFLs5xVQ
2025-07-15 18:27:00.165 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=BookAnythingBackendApplication-producer-1] ProducerId set to 1 with epoch 0
2025-07-15 18:27:00.190 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=278e7894-d24d-46bb-994d-805dff7566a2, nome=CD Kafka Teste
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-test-group-14, groupId=test-group] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer - test-group: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Member consumer-geojson-processor-11-83f152a2-5f04-4a08-a40a-cc8cc11367ab sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-10-5344cdb7-5857-49d3-8e12-b965655fbd29 sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-13-6f40acd3-f02f-49ac-a6fc-55f6ca197aee sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Member consumer-test-group-14-005036a1-1001-4c7d-9adb-4c0d3ff9162a sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.211 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-test-group-14, groupId=test-group] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-test-group-14, groupId=test-group] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.212 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=278e7894-d24d-46bb-994d-805dff7566a2, nome=CD Kafka Teste
2025-07-15 18:27:00.260 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:27:00.260 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:27:00.260 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-12-b0d93c88-d6bf-46ce-a255-292e3b4a5b18 sending LeaveGroup request to coordinator localhost:34697 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:27:00.260 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.260 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.260 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:27:00.261 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.261 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-12, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:27:00.477 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-all-10, groupId=elasticsearch-deleter-all] Node 1 sent an invalid full fetch response with extraIds=(lV7-XdWfR8-uT1Qen5GJ1Q), response=()
2025-07-15 18:27:00.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:27:00.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:27:00.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:27:00.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:27:00.480 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-10 unregistered
2025-07-15 18:27:00.480 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:27:00.492 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-11, groupId=geojson-processor] Node 1 sent an invalid full fetch response with extraIds=(U1E9B1-bTb6kBrciUwT9Vg), response=()
2025-07-15 18:27:00.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:27:00.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:27:00.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:27:00.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:27:00.497 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-11 unregistered
2025-07-15 18:27:00.497 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:27:00.507 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-13, groupId=elasticsearch-deleter] Node 1 sent an invalid full fetch response with extraIds=(brmeU2eAQ6m0Scsq0SK1nQ), response=()
2025-07-15 18:27:00.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:27:00.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:27:00.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:27:00.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:27:00.509 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-13 unregistered
2025-07-15 18:27:00.510 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:27:00.696 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:27:00.696 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:27:00.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:27:00.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:27:00.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:27:00.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:27:00.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:27:00.697 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:27:00.705 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-test-group-14 unregistered
2025-07-15 18:27:00.706 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-12 unregistered
2025-07-15 18:27:00.707 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] o.s.k.l.KafkaMessageListenerContainer - test-group: Consumer stopped
2025-07-15 18:27:00.707 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:27:00.708 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-07-15 18:27:00.710 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:27:00.710 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:27:00.710 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:27:00.710 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:27:00.710 INFO  [main] o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for BookAnythingBackendApplication-producer-1 unregistered
2025-07-15 18:27:00.714 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:27:00.715 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:27:00.717 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.94 s -- in de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceCreationIntegrationTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest
2025-07-15 18:27:02.193 INFO  [main] tc.elasticsearch:8.14.0 - Creating container for image: elasticsearch:8.14.0
2025-07-15 18:27:02.277 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 is starting: edfd4b03a42a38d5dea2f5a993c60cb9f5208d84fc9791747040f1fc3f8d0379
2025-07-15 18:27:27.375 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 started in PT25.18203276S
2025-07-15 18:27:27.376 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Creating container for image: confluentinc/cp-kafka:7.6.0
2025-07-15 18:27:27.453 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 is starting: 6d9641e0248e36f87b77815ae03c27ce3cfd064988b0f6084faba237f04738ba
2025-07-15 18:27:33.805 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 started in PT6.428942832S
2025-07-15 18:27:33.806 INFO  [main] tc.keycloak/keycloak:26.3.1 - Creating container for image: keycloak/keycloak:26.3.1
2025-07-15 18:27:33.920 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 is starting: 7e2d520e619b1b12ca8ed92c79372c24b8908e5d1e701d560106ad454203bd1a
2025-07-15 18:27:34.177 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
2025-07-15 18:27:34.184 INFO  [main] o.t.c.wait.strategy.HttpWaitStrategy - /funny_pasteur: Waiting for 120 seconds for URL: http://localhost:34708/health/started (where port 34708 maps to container port 9000)
2025-07-15 18:27:35.229 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
2025-07-15 18:27:45.815 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:45,814 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 9573ms
2025-07-15 18:27:46.777 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: Running the server in development mode. DO NOT use this configuration in production.
2025-07-15 18:27:52.072 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:52,070 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
2025-07-15 18:27:56.035 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:56,034 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
2025-07-15 18:27:56.352 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:56,351 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
2025-07-15 18:27:56.812 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:56,810 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_200064, Site name: null
2025-07-15 18:27:57.057 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:57,057 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
2025-07-15 18:27:57.064 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:57,064 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
2025-07-15 18:27:58.686 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:27:58,685 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
2025-07-15 18:28:01.717 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:28:01,716 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
2025-07-15 18:28:01.722 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:28:01,721 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
2025-07-15 18:28:01.877 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:28:01,876 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
2025-07-15 18:28:02.096 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:28:02,095 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 16.106s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
2025-07-15 18:28:02.096 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:28:02,095 INFO  [io.quarkus] (main) Profile dev activated. 
2025-07-15 18:28:02.096 INFO  [docker-java-stream-1233091373] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:28:02,096 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
2025-07-15 18:28:02.362 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 started in PT28.556628003S
2025-07-15 18:28:02.363 INFO  [main] tc.postgis/postgis:16-3.4 - Creating container for image: postgis/postgis:16-3.4
2025-07-15 18:28:02.428 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 is starting: a60d0b72e69ecf3561d26f28a1eabc5576783c588c64a5ba0fe4cbaf8ab55404
2025-07-15 18:28:05.038 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 started in PT2.67543534S
2025-07-15 18:28:05.039 INFO  [main] tc.postgis/postgis:16-3.4 - Container is started (JDBC URL: jdbc:postgresql://localhost:34709/DBBookAnythingPlatform?loggerLevel=OFF)
2025-07-15 18:28:05.041 INFO  [main] o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest]: LocalizablePlaceDeletionIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-07-15 18:28:05.044 INFO  [main] o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:28:05.070 INFO  [main] d.o.d.b.d.LocalizablePlaceDeletionIntegrationTest - Starting LocalizablePlaceDeletionIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:28:05.070 INFO  [main] d.o.d.b.d.LocalizablePlaceDeletionIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:28:05.285 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:28:05.286 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.293 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:28:05.297 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 9 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:28:05.299 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:28:05.299 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:28:05.304 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:28:05.311 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 11 ms. Found 8 JPA repository interfaces.
2025-07-15 18:28:05.411 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:28:05.456 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@440404f5
2025-07-15 18:28:05.457 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:28:05.468 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:28:05.510 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:28:05.518 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:28:05.531 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:28:05.553 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:28:05.555 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:28:05.557 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:28:05.557 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:28:05.583 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:28:05.588 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:28:05.589 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:28:05.595 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:28:05.596 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:28:05.602 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:28:05.604 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:28:05.656 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:28:05.712 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:28:05.713 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@59773c5d] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:28:05.763 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:28:05.763 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:28:05.769 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:28:06.897 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:28:07.095 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:28:07.095 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:28:07.096 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 1 ms
2025-07-15 18:28:07.121 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34705]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:28:07.122 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:28:07.124 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:28:07.124 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:28:07.124 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596887124
2025-07-15 18:28:07.127 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:28:07.130 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34705]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:28:07.131 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:28:07.137 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:28:07.137 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:28:07.137 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596887137
2025-07-15 18:28:07.140 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:28:07.142 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34705]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:28:07.143 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:28:07.146 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:28:07.146 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:28:07.146 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596887146
2025-07-15 18:28:07.150 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:28:07.153 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34705]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:28:07.154 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:28:07.156 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:28:07.156 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:28:07.156 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596887156
2025-07-15 18:28:07.161 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:28:07.163 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:28:07.242 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.242 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.242 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.242 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.242 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Cluster ID: oFUveWC4TaqjqinSiR15wA
2025-07-15 18:28:07.242 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Cluster ID: oFUveWC4TaqjqinSiR15wA
2025-07-15 18:28:07.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Cluster ID: oFUveWC4TaqjqinSiR15wA
2025-07-15 18:28:07.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Cluster ID: oFUveWC4TaqjqinSiR15wA
2025-07-15 18:28:07.291 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:28:07.298 INFO  [main] d.o.d.b.d.LocalizablePlaceDeletionIntegrationTest - Started LocalizablePlaceDeletionIntegrationTest in 2.25 seconds (process running for 217.712)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:28:07.356 INFO  [main] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:34705]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = BookAnythingBackendApplication-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 52428800
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-07-15 18:28:07.357 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:28:07.359 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Instantiated an idempotent producer.
2025-07-15 18:28:07.364 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:28:07.364 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:28:07.364 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596887364
2025-07-15 18:28:07.365 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.365 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.380 WARN  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.apache.kafka.clients.NetworkClient - [Producer clientId=BookAnythingBackendApplication-producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.380 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=BookAnythingBackendApplication-producer-1] Cluster ID: oFUveWC4TaqjqinSiR15wA
2025-07-15 18:28:07.383 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.402 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.512 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=BookAnythingBackendApplication-producer-1] ProducerId set to 0 with epoch 0
2025-07-15 18:28:07.517 WARN  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.apache.kafka.clients.NetworkClient - [Producer clientId=BookAnythingBackendApplication-producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 8 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.561 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:28:07.639 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34705 (id: 2147483646 rack: null)
2025-07-15 18:28:07.640 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:28:07.656 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-18-5126171c-b6e9-4cd2-9cbf-797b8ae5717e
2025-07-15 18:28:07.657 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:28:07.675 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-18-5126171c-b6e9-4cd2-9cbf-797b8ae5717e', protocol='range'}
2025-07-15 18:28:07.675 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-18-5126171c-b6e9-4cd2-9cbf-797b8ae5717e=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:28:07.732 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-18-5126171c-b6e9-4cd2-9cbf-797b8ae5717e', protocol='range'}
2025-07-15 18:28:07.733 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:28:07.733 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:28:07.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
2025-07-15 18:28:07.757 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:28:07.772 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34705 (id: 1 rack: null)], epoch=0}}.
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:28:07.800 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:28:07.986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34705 (id: 2147483646 rack: null)
2025-07-15 18:28:07.988 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:28:07.995 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Discovered group coordinator localhost:34705 (id: 2147483646 rack: null)
2025-07-15 18:28:07.995 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-15-25052fa3-7223-4a7c-81d3-94f1bb7ee276
2025-07-15 18:28:07.996 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:28:07.997 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:28:08.000 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-15-25052fa3-7223-4a7c-81d3-94f1bb7ee276', protocol='range'}
2025-07-15 18:28:08.001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-15-25052fa3-7223-4a7c-81d3-94f1bb7ee276=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
2025-07-15 18:28:08.002 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-16-64bbf673-a590-42ba-8390-5ae4e4a34be8
2025-07-15 18:28:08.002 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:28:08.005 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-15-25052fa3-7223-4a7c-81d3-94f1bb7ee276', protocol='range'}
2025-07-15 18:28:08.005 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-16-64bbf673-a590-42ba-8390-5ae4e4a34be8', protocol='range'}
2025-07-15 18:28:08.006 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:28:08.006 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:28:08.006 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-16-64bbf673-a590-42ba-8390-5ae4e4a34be8=Assignment(partitions=[geojson-upload-topic-0])}
2025-07-15 18:28:08.008 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:28:08.011 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:28:08.011 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-16-64bbf673-a590-42ba-8390-5ae4e4a34be8', protocol='range'}
2025-07-15 18:28:08.012 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:28:08.012 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:28:08.014 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:28:08.014 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34705 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:28:08.016 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:28:08.017 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34705 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:28:08.018 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:28:08.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:28:08.044 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34705 (id: 2147483646 rack: null)
2025-07-15 18:28:08.045 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:28:08.051 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-17-83df9110-3d10-41e0-9681-bee1c24145c7
2025-07-15 18:28:08.052 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:28:08.059 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-17-83df9110-3d10-41e0-9681-bee1c24145c7', protocol='range'}
2025-07-15 18:28:08.061 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-17-83df9110-3d10-41e0-9681-bee1c24145c7=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:28:08.067 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-17-83df9110-3d10-41e0-9681-bee1c24145c7', protocol='range'}
2025-07-15 18:28:08.067 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:28:08.067 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:28:08.070 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:28:08.071 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:28:08.073 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34705 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:28:08.076 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 
Documents found in ElasticSearch: 

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"106"]
             Body = {"name":"One New LocalizablePlace - No.: 0","latitude":-23.558974978968724,"longitude":-46.63399705773383}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/025b31e6-b440-4ba0-ab64-cdf93bdac8e3", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"025b31e6-b440-4ba0-ab64-cdf93bdac8e3","name":"One New LocalizablePlace - No.: 0","latitude":-23.558974978968724,"longitude":-46.63399705773383}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/025b31e6-b440-4ba0-ab64-cdf93bdac8e3
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"106"]
             Body = {"name":"One New LocalizablePlace - No.: 1","latitude":-23.55114375673341,"longitude":-46.633326675462015}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/e65dcac6-53bf-483f-aa4d-b630db6ba4ff", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"e65dcac6-53bf-483f-aa4d-b630db6ba4ff","name":"One New LocalizablePlace - No.: 1","latitude":-23.55114375673341,"longitude":-46.633326675462015}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/e65dcac6-53bf-483f-aa4d-b630db6ba4ff
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"105"]
             Body = {"name":"One New LocalizablePlace - No.: 2","latitude":-23.557001650444406,"longitude":-46.6331834098607}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/17542e55-4125-46fd-a90d-dd60c54eec46", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"17542e55-4125-46fd-a90d-dd60c54eec46","name":"One New LocalizablePlace - No.: 2","latitude":-23.557001650444406,"longitude":-46.6331834098607}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/17542e55-4125-46fd-a90d-dd60c54eec46
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"106"]
             Body = {"name":"One New LocalizablePlace - No.: 3","latitude":-23.557144180145958,"longitude":-46.63308302300193}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/af6bfeb9-34bb-4907-a161-8c2e3117183f", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"af6bfeb9-34bb-4907-a161-8c2e3117183f","name":"One New LocalizablePlace - No.: 3","latitude":-23.557144180145958,"longitude":-46.63308302300193}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/af6bfeb9-34bb-4907-a161-8c2e3117183f
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"107"]
             Body = {"name":"One New LocalizablePlace - No.: 4","latitude":-23.551392513204544,"longitude":-46.633247604874434}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/ec9b31a1-5a12-49b1-a286-e8777f978fb3", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"ec9b31a1-5a12-49b1-a286-e8777f978fb3","name":"One New LocalizablePlace - No.: 4","latitude":-23.551392513204544,"longitude":-46.633247604874434}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/ec9b31a1-5a12-49b1-a286-e8777f978fb3
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"105"]
             Body = {"name":"One New LocalizablePlace - No.: 5","latitude":-23.556722453190083,"longitude":-46.6330125974958}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/4f5308b6-c2b5-411d-8aa6-9abc94ffa3e4", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"4f5308b6-c2b5-411d-8aa6-9abc94ffa3e4","name":"One New LocalizablePlace - No.: 5","latitude":-23.556722453190083,"longitude":-46.6330125974958}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/4f5308b6-c2b5-411d-8aa6-9abc94ffa3e4
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"106"]
             Body = {"name":"One New LocalizablePlace - No.: 6","latitude":-23.550741442491542,"longitude":-46.63398426990083}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/bbf5d483-b303-4dfc-810c-5cd35b5deca2", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"bbf5d483-b303-4dfc-810c-5cd35b5deca2","name":"One New LocalizablePlace - No.: 6","latitude":-23.550741442491542,"longitude":-46.63398426990083}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/bbf5d483-b303-4dfc-810c-5cd35b5deca2
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"107"]
             Body = {"name":"One New LocalizablePlace - No.: 7","latitude":-23.550483691269932,"longitude":-46.633450263763265}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/f628ad8a-cf7f-4a81-be9e-4f7154577894", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"f628ad8a-cf7f-4a81-be9e-4f7154577894","name":"One New LocalizablePlace - No.: 7","latitude":-23.550483691269932,"longitude":-46.633450263763265}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/f628ad8a-cf7f-4a81-be9e-4f7154577894
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"106"]
             Body = {"name":"One New LocalizablePlace - No.: 8","latitude":-23.553228984986458,"longitude":-46.63311182034648}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/eef84506-9aae-43a4-93a1-cfc443bbddfd", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"eef84506-9aae-43a4-93a1-cfc443bbddfd","name":"One New LocalizablePlace - No.: 8","latitude":-23.553228984986458,"longitude":-46.63311182034648}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/eef84506-9aae-43a4-93a1-cfc443bbddfd
          Cookies = []

MockHttpServletRequest:
      HTTP Method = POST
      Request URI = /api/v1/localizable-places
       Parameters = {}
          Headers = [Content-Type:"application/json;charset=UTF-8", Content-Length:"106"]
             Body = {"name":"One New LocalizablePlace - No.: 9","latitude":-23.55769052442687,"longitude":-46.633903587636674}
    Session Attrs = {}

Handler:
             Type = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController
           Method = de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.LocalizablePlaceController#create(CreateLocalizablePlaceRestRequest)

Async:
    Async started = false
     Async result = null

Resolved Exception:
             Type = null

ModelAndView:
        View name = null
             View = null
            Model = null

FlashMap:
       Attributes = null

MockHttpServletResponse:
           Status = 201
    Error message = null
          Headers = [Location:"http://localhost/api/v1/localizable-places/0532b304-14ce-44c6-82a8-99e515d314bd", Content-Type:"application/json", X-Content-Type-Options:"nosniff", X-XSS-Protection:"0", Cache-Control:"no-cache, no-store, max-age=0, must-revalidate", Pragma:"no-cache", Expires:"0", X-Frame-Options:"DENY"]
     Content type = application/json
             Body = {"id":"0532b304-14ce-44c6-82a8-99e515d314bd","name":"One New LocalizablePlace - No.: 9","latitude":-23.55769052442687,"longitude":-46.633903587636674}
    Forwarded URL = null
   Redirected URL = http://localhost/api/v1/localizable-places/0532b304-14ce-44c6-82a8-99e515d314bd
          Cookies = []
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:28:38.052 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=a578c8b6-e843-4ab2-a0bb-3e8439db4a27, nome=LocalizablePlace To Delete
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
2025-07-15 18:28:38.137 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:28:38.137 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Member consumer-geojson-processor-16-64bbf673-a590-42ba-8390-5ae4e4a34be8 sending LeaveGroup request to coordinator localhost:34705 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-15-25052fa3-7223-4a7c-81d3-94f1bb7ee276 sending LeaveGroup request to coordinator localhost:34705 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:28:38.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:28:38.139 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.139 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.139 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-16, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.139 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-15, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
Localizable Place removed successfully from ElasticSearch: a578c8b6-e843-4ab2-a0bb-3e8439db4a27
2025-07-15 18:28:38.233 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:28:38.234 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:28:38.234 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-18-5126171c-b6e9-4cd2-9cbf-797b8ae5717e sending LeaveGroup request to coordinator localhost:34705 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:28:38.235 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.235 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.235 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:28:38.235 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.236 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-18, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.252 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=a578c8b6-e843-4ab2-a0bb-3e8439db4a27, nome=LocalizablePlace To Delete
2025-07-15 18:28:38.255 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:28:38.255 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:28:38.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-17-83df9110-3d10-41e0-9681-bee1c24145c7 sending LeaveGroup request to coordinator localhost:34705 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:28:38.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:28:38.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.256 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-17, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:28:38.286 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:28:38.286 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:28:38.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:28:38.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:28:38.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:28:38.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:28:38.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:28:38.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:28:38.291 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-15 unregistered
2025-07-15 18:28:38.291 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-16 unregistered
2025-07-15 18:28:38.291 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:28:38.291 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:28:38.557 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:28:38.558 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:28:38.558 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:28:38.558 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:28:38.564 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-17 unregistered
2025-07-15 18:28:38.565 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:28:38.595 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:28:38.596 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:28:38.596 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:28:38.596 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:28:38.600 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-18 unregistered
2025-07-15 18:28:38.601 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:28:38.601 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-07-15 18:28:38.609 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:28:38.610 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:28:38.610 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:28:38.610 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:28:38.610 INFO  [main] o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for BookAnythingBackendApplication-producer-1 unregistered
2025-07-15 18:28:38.613 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:28:38.614 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:28:38.617 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.
[ERROR] Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 97.80 s <<< FAILURE! -- in de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest
[ERROR] de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest.shouldDeleteAllLocalizablePlaces -- Time elapsed: 30.72 s <<< ERROR!
org.awaitility.core.ConditionTimeoutException: Assertion condition defined as a Lambda expression in de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest expected: <10> but was: <0> within 30 seconds.
	at org.awaitility.core.ConditionAwaiter.await(ConditionAwaiter.java:167)
	at org.awaitility.core.AssertionCondition.await(AssertionCondition.java:119)
	at org.awaitility.core.AssertionCondition.await(AssertionCondition.java:31)
	at org.awaitility.core.ConditionFactory.until(ConditionFactory.java:1006)
	at org.awaitility.core.ConditionFactory.untilAsserted(ConditionFactory.java:790)
	at de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest.shouldDeleteAllLocalizablePlaces(LocalizablePlaceDeletionIntegrationTest.kt:72)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
	at java.base/java.util.ArrayList.forEach(ArrayList.java:1596)
Caused by: org.opentest4j.AssertionFailedError: expected: <10> but was: <0>
	at org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:151)
	at org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132)
	at org.junit.jupiter.api.AssertEquals.failNotEqual(AssertEquals.java:197)
	at org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:150)
	at org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:145)
	at org.junit.jupiter.api.Assertions.assertEquals(Assertions.java:531)
	at de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest.shouldDeleteAllLocalizablePlaces$lambda$12(LocalizablePlaceDeletionIntegrationTest.kt:90)
	at org.awaitility.core.AssertionCondition.lambda$new$0(AssertionCondition.java:53)
	at org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:248)
	at org.awaitility.core.ConditionAwaiter$ConditionPoller.call(ConditionAwaiter.java:235)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)

[INFO] Running de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceLocatorApplicationTests
2025-07-15 18:28:39.999 INFO  [main] tc.elasticsearch:8.14.0 - Creating container for image: elasticsearch:8.14.0
2025-07-15 18:28:40.088 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 is starting: 976df795b31a5f1781a8e2944ddd44db8b37a451205c92ea68a89824b1319d73
2025-07-15 18:29:00.910 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 started in PT20.910449205S
2025-07-15 18:29:00.910 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Creating container for image: confluentinc/cp-kafka:7.6.0
2025-07-15 18:29:00.978 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 is starting: 49f8b664811bb62ca42b2ab2c8a775702247826aca0c4a611233487d1c86ea04
2025-07-15 18:29:07.371 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 started in PT6.461376096S
2025-07-15 18:29:07.372 INFO  [main] tc.keycloak/keycloak:26.3.1 - Creating container for image: keycloak/keycloak:26.3.1
2025-07-15 18:29:07.503 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 is starting: f3cec8fe4fc313bbd8f94cd4400420013c3f30a94a9dcd8c48427bbaaf11a4ac
2025-07-15 18:29:07.757 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
2025-07-15 18:29:07.764 INFO  [main] o.t.c.wait.strategy.HttpWaitStrategy - /hardcore_edison: Waiting for 120 seconds for URL: http://localhost:34716/health/started (where port 34716 maps to container port 9000)
2025-07-15 18:29:08.776 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
2025-07-15 18:29:19.422 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:19,421 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 9726ms
2025-07-15 18:29:20.357 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: Running the server in development mode. DO NOT use this configuration in production.
2025-07-15 18:29:25.451 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:25,449 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
2025-07-15 18:29:29.472 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:29,472 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
2025-07-15 18:29:29.730 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:29,729 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
2025-07-15 18:29:30.247 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:30,247 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_167856, Site name: null
2025-07-15 18:29:30.470 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:30,469 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
2025-07-15 18:29:30.480 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:30,479 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
2025-07-15 18:29:32.177 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:32,176 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
2025-07-15 18:29:34.841 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:34,840 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
2025-07-15 18:29:34.846 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:34,845 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
2025-07-15 18:29:35.008 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:35,008 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
2025-07-15 18:29:35.210 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:35,209 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 15.612s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
2025-07-15 18:29:35.210 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:35,210 INFO  [io.quarkus] (main) Profile dev activated. 
2025-07-15 18:29:35.210 INFO  [docker-java-stream-330528345] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:29:35,210 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
2025-07-15 18:29:36.052 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 started in PT28.679997392S
2025-07-15 18:29:36.053 INFO  [main] tc.postgis/postgis:16-3.4 - Creating container for image: postgis/postgis:16-3.4
2025-07-15 18:29:36.162 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 is starting: cdb533af7f8bc3663260f18e1a6b216c4a122151f1b888cd345108253072f2d4
2025-07-15 18:29:39.504 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 started in PT3.450465738S
2025-07-15 18:29:39.504 INFO  [main] tc.postgis/postgis:16-3.4 - Container is started (JDBC URL: jdbc:postgresql://localhost:34717/DBBookAnythingPlatform?loggerLevel=OFF)
2025-07-15 18:29:39.506 INFO  [main] o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceLocatorApplicationTests]: LocalizablePlaceLocatorApplicationTests does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-07-15 18:29:39.508 INFO  [main] o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceLocatorApplicationTests

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:29:39.538 INFO  [main] d.o.d.b.d.LocalizablePlaceLocatorApplicationTests - Starting LocalizablePlaceLocatorApplicationTests using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:29:39.538 INFO  [main] d.o.d.b.d.LocalizablePlaceLocatorApplicationTests - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:29:39.821 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:29:39.821 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.830 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:29:39.835 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 13 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:29:39.839 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:29:39.840 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:29:39.849 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:29:39.861 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 19 ms. Found 8 JPA repository interfaces.
2025-07-15 18:29:40.014 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:29:40.031 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@5fefc31
2025-07-15 18:29:40.031 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:29:40.041 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:29:40.074 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:29:40.084 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:29:40.098 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:29:40.129 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:29:40.131 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:29:40.134 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:29:40.135 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:29:40.135 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:29:40.135 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:29:40.135 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:29:40.135 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:29:40.135 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:29:40.135 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:29:40.179 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:29:40.184 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:29:40.186 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:29:40.201 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:29:40.201 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:29:40.210 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:29:40.211 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:29:40.308 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:29:40.373 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:29:40.374 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@6d77e629] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:29:40.431 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:29:40.432 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:29:40.442 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:29:42.473 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:29:42.779 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34713]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:29:42.780 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:29:42.784 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:29:42.784 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:29:42.784 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596982784
2025-07-15 18:29:42.786 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:29:42.790 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34713]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:29:42.791 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:29:42.795 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:29:42.796 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:29:42.796 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596982795
2025-07-15 18:29:42.798 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:29:42.801 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34713]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-21
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:29:42.802 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:29:42.806 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:29:42.806 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:29:42.806 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596982806
2025-07-15 18:29:42.810 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:29:42.815 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34713]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-22
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:29:42.822 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:29:42.827 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:29:42.828 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:29:42.828 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752596982827
2025-07-15 18:29:42.833 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:29:42.835 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:29:42.949 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:42.949 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:42.949 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:42.949 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:42.949 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Cluster ID: G07rhl1nQ46e_K8zu_k5_w
2025-07-15 18:29:42.949 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Cluster ID: G07rhl1nQ46e_K8zu_k5_w
2025-07-15 18:29:42.949 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Cluster ID: G07rhl1nQ46e_K8zu_k5_w
2025-07-15 18:29:42.951 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Cluster ID: G07rhl1nQ46e_K8zu_k5_w
2025-07-15 18:29:42.999 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:29:43.008 INFO  [main] d.o.d.b.d.LocalizablePlaceLocatorApplicationTests - Started LocalizablePlaceLocatorApplicationTests in 3.495 seconds (process running for 313.422)
2025-07-15 18:29:43.106 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.106 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.108 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.125 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.288 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.323 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.367 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.375 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:29:43.760 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34713 (id: 2147483646 rack: null)
2025-07-15 18:29:43.763 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:29:43.768 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34713 (id: 2147483646 rack: null)
2025-07-15 18:29:43.769 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Discovered group coordinator localhost:34713 (id: 2147483646 rack: null)
2025-07-15 18:29:43.770 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:29:43.770 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:29:43.796 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-22-fa30e737-4f63-427f-9f08-5030667700f6
2025-07-15 18:29:43.796 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:29:43.801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-19-39e7d8bc-9d50-4200-b7f8-2a0fb9512f26
2025-07-15 18:29:43.801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-20-2275044c-e444-4982-803a-0a8bc3df73fc
2025-07-15 18:29:43.801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:29:43.801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:29:43.812 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34713 (id: 2147483646 rack: null)
2025-07-15 18:29:43.813 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:29:43.823 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-21-9766087f-c1ae-448e-bc79-77b42452e461
2025-07-15 18:29:43.824 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:29:43.838 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-20-2275044c-e444-4982-803a-0a8bc3df73fc', protocol='range'}
2025-07-15 18:29:43.841 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-20-2275044c-e444-4982-803a-0a8bc3df73fc=Assignment(partitions=[geojson-upload-topic-0])}
2025-07-15 18:29:43.845 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-19-39e7d8bc-9d50-4200-b7f8-2a0fb9512f26', protocol='range'}
2025-07-15 18:29:43.846 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-19-39e7d8bc-9d50-4200-b7f8-2a0fb9512f26=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
2025-07-15 18:29:43.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-22-fa30e737-4f63-427f-9f08-5030667700f6', protocol='range'}
2025-07-15 18:29:43.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-22-fa30e737-4f63-427f-9f08-5030667700f6=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:29:43.851 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-21-9766087f-c1ae-448e-bc79-77b42452e461', protocol='range'}
2025-07-15 18:29:43.852 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-21-9766087f-c1ae-448e-bc79-77b42452e461=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:29:43.970 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-19-39e7d8bc-9d50-4200-b7f8-2a0fb9512f26', protocol='range'}
2025-07-15 18:29:43.970 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-22-fa30e737-4f63-427f-9f08-5030667700f6', protocol='range'}
2025-07-15 18:29:43.970 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-20-2275044c-e444-4982-803a-0a8bc3df73fc', protocol='range'}
2025-07-15 18:29:43.971 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-21-9766087f-c1ae-448e-bc79-77b42452e461', protocol='range'}
2025-07-15 18:29:43.971 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:29:43.971 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:29:43.971 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:29:43.971 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:29:43.972 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:29:43.972 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:29:43.973 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:29:43.973 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:29:43.993 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:29:43.995 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:29:43.995 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:29:44.000 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:29:44.000 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:29:44.000 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:29:44.001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:29:44.006 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:29:44.027 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34713 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:29:44.027 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34713 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:29:44.027 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34713 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:29:44.027 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34713 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:29:44.077 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:29:44.077 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:29:44.077 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:29:44.078 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:29:44.229 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 2147483646 disconnected.
2025-07-15 18:29:44.229 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 2147483646 disconnected.
2025-07-15 18:29:44.229 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 2147483646 disconnected.
2025-07-15 18:29:44.229 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:44.231 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Cancelled in-flight FETCH request with correlation id 22 due to node 1 being disconnected (elapsed time since creation: 151ms, elapsed time since send: 151ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.232 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node -1 disconnected.
2025-07-15 18:29:44.232 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 2147483646 disconnected.
2025-07-15 18:29:44.232 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Group coordinator localhost:34713 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter-all] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-indexer] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter-all] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Cancelled in-flight FETCH request with correlation id 22 due to node 1 being disconnected (elapsed time since creation: 155ms, elapsed time since send: 155ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Cancelled in-flight FETCH request with correlation id 22 due to node 1 being disconnected (elapsed time since creation: 154ms, elapsed time since send: 154ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter-all] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Cancelled in-flight METADATA request with correlation id 23 due to node 1 being disconnected (elapsed time since creation: 56ms, elapsed time since send: 56ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Cancelled in-flight METADATA request with correlation id 23 due to node 1 being disconnected (elapsed time since creation: 55ms, elapsed time since send: 55ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-indexer] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Cancelled in-flight FETCH request with correlation id 22 due to node 1 being disconnected (elapsed time since creation: 153ms, elapsed time since send: 153ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter-all] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node -1 disconnected.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-indexer] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Cancelled in-flight METADATA request with correlation id 23 due to node 1 being disconnected (elapsed time since creation: 54ms, elapsed time since send: 54ms, throttle time: 0ms, request timeout: 30000ms)
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node -1 disconnected.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-indexer] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node -1 disconnected.
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-indexer] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter-all] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:29:44.233 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:29:44.233 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:29:44.236 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-deleter-all] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Group coordinator localhost:34713 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-07-15 18:29:44.236 INFO  [kafka-coordinator-heartbeat-thread | elasticsearch-indexer] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Group coordinator localhost:34713 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-07-15 18:29:44.236 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Group coordinator localhost:34713 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: true. Rediscovery will be attempted.
2025-07-15 18:29:44.321 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:44.322 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.333 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:44.333 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.338 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:44.338 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.351 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:44.351 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.435 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:44.435 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.441 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:44.441 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.451 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:44.451 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.579 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:44.579 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.644 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:44.645 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.667 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:44.668 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:44.690 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:44.690 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 65.00 s -- in de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceLocatorApplicationTests
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.SearchNearestLocalizablePlacesIntegrationTest
2025-07-15 18:29:45.003 INFO  [main] tc.elasticsearch:8.14.0 - Creating container for image: elasticsearch:8.14.0
2025-07-15 18:29:45.058 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:45.058 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.080 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:45.080 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.092 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 is starting: 411a998f283dbdbf863a28aec3cdc166773c50ac785725e20790f5e68e095439
2025-07-15 18:29:45.123 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:45.123 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.129 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:45.130 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.776 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:45.777 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.855 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:45.855 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.865 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:45.866 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:45.930 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:45.931 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:46.778 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:46.778 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:46.810 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:46.810 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:46.851 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:46.852 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:46.911 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:46.912 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:47.779 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:47.779 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:47.801 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:47.802 WARN  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:47.812 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:47.812 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:47.875 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:47.875 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:48.777 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:48.778 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:48.779 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:48.779 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:48.802 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:48.803 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:48.813 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:48.813 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:49.781 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:49.782 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:49.786 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:49.786 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:49.803 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:49.803 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:49.813 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:49.814 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:50.676 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:50.676 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:50.771 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:50.771 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:50.788 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:50.789 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:50.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:50.848 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:51.631 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:51.632 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:51.772 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:51.772 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:51.788 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:51.788 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:51.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:51.849 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:52.633 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:52.633 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:52.773 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:52.774 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:52.793 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:52.794 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:52.804 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:52.804 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:52.805 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:29:53.591 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:53.591 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:53.775 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:53.775 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:53.793 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:53.793 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:53.793 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:53.794 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:54.591 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:54.592 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:54.775 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:54.776 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:54.794 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:54.794 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:54.794 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:54.794 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:55.592 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:55.593 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:55.776 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:55.777 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:55.795 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:55.795 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:55.795 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:55.795 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:56.619 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:56.620 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:56.702 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:56.702 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:56.778 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:56.778 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:56.798 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:56.798 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:57.620 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:57.620 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:57.741 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:57.742 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:57.780 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:57.780 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:57.801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:57.801 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:58.621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:58.622 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:58.744 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:58.744 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:58.783 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:58.783 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:58.802 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:58.802 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:59.623 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:29:59.624 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:59.746 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:29:59.746 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:59.784 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:29:59.784 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:29:59.804 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:29:59.804 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:00.625 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:00.625 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:00.749 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:00.750 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:00.786 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:00.787 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:00.806 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:00.807 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:01.626 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:01.626 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:01.750 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:01.751 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:01.787 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:01.787 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:01.808 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:01.808 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:02.627 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:02.628 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:02.762 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:02.763 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:02.796 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:02.797 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:02.810 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:02.810 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:03.628 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:03.629 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:03.677 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:03.677 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:03.799 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:03.800 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:03.803 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:03.803 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:04.630 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:04.630 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:04.678 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:04.678 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:04.800 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:04.800 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:04.804 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:04.804 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:05.631 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:05.631 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:05.679 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:05.679 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:05.802 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:05.803 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:05.806 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:05.806 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:06.646 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:06.646 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:06.681 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:06.681 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:06.804 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:06.804 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:06.810 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:06.811 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:07.647 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:07.647 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:07.682 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:07.682 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:07.806 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:07.806 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:07.888 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:07.889 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:08.648 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:08.648 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:08.683 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:08.683 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:08.807 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:08.807 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:08.889 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:08.891 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:09.588 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:09.588 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:09.649 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:09.650 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:09.808 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:09.809 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:09.890 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:09.890 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:10.452 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:10.452 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:10.453 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 started in PT25.44959787S
2025-07-15 18:30:10.453 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Creating container for image: confluentinc/cp-kafka:7.6.0
2025-07-15 18:30:10.532 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 is starting: a8db5c0eb0014c74793db25433c379864a5aaa613827391fad544cd0ad838225
2025-07-15 18:30:10.691 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:10.692 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:10.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:10.810 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:10.891 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:10.891 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:11.454 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:11.454 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:11.692 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:11.693 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:11.810 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:11.811 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:11.892 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:11.892 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:12.456 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:12.456 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:12.621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:12.621 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:12.811 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:12.812 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:12.897 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:12.897 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:13.479 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:13.479 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:13.662 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:13.662 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:13.801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:13.801 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:13.812 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:13.812 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:14.480 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:14.481 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:14.668 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:14.668 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:14.813 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:14.814 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:14.823 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:14.823 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:15.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:15.481 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:15.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:15.671 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:15.814 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:15.814 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:15.825 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:15.825 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:16.482 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:16.482 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:16.672 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:16.672 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:16.815 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:16.816 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:16.826 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:16.827 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:17.213 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 started in PT6.760155908S
2025-07-15 18:30:17.215 INFO  [main] tc.keycloak/keycloak:26.3.1 - Creating container for image: keycloak/keycloak:26.3.1
2025-07-15 18:30:17.329 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 is starting: a227761974b45461c9d9bb12dbb06b5021d60be5cc2432983c1c2583323286c2
2025-07-15 18:30:17.483 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:17.484 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:17.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:17.577 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:17.581 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
2025-07-15 18:30:17.587 INFO  [main] o.t.c.wait.strategy.HttpWaitStrategy - /nifty_lamarr: Waiting for 120 seconds for URL: http://localhost:34724/health/started (where port 34724 maps to container port 9000)
2025-07-15 18:30:17.816 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:17.817 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:17.894 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:17.894 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:18.443 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:18.444 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:18.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:18.494 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:18.517 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
2025-07-15 18:30:18.817 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:18.817 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:18.895 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:18.895 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:19.445 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:19.445 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:19.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:19.494 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:19.819 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:19.819 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:19.897 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:19.897 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:20.446 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:20.447 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:20.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:20.494 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:20.741 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:20.741 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:20.939 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:20.939 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:21.452 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:21.452 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:21.496 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:21.497 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:21.677 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:21.677 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:21.942 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:21.943 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:22.454 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:22.455 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:22.498 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:22.499 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:22.679 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:22.680 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:22.813 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:22.814 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:22.814 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:30:23.455 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:23.455 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:23.500 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:23.500 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:23.684 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:23.684 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:23.807 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:23.811 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:24.457 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:24.457 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:24.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:24.509 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:24.684 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:24.684 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:24.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:24.810 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:25.459 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:25.460 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:25.542 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:25.542 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:25.637 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:25.637 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:25.811 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:25.812 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:26.460 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:26.460 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:26.521 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:26.521 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:26.645 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:26.646 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:26.813 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:26.813 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:27.352 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:27.352 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:27.502 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:27.502 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:27.646 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:27.646 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:27.815 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:27.816 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:28.266 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:28.267 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:28.525 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:28.526 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:28.647 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:28.647 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:28.816 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:28.816 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:29.272 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:29.272 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:29.526 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:29.527 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:29.648 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:29.649 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:29.654 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:29,652 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 10255ms
2025-07-15 18:30:29.761 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:29.761 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:30.278 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:30.278 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:30.432 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:30.432 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:30.616 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:30.617 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:30.649 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:30.649 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:30.845 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: Running the server in development mode. DO NOT use this configuration in production.
2025-07-15 18:30:31.279 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:31.279 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:31.414 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:31.414 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:31.617 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:31.618 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:31.650 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:31.651 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:32.280 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:32.280 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:32.420 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:32.420 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:32.618 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:32.618 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:32.651 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:32.651 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:33.282 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:33.282 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:33.421 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:33.422 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:33.613 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:33.613 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:33.619 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:33.620 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:34.283 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:34.283 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:34.421 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:34.421 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:34.619 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:34.619 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:34.620 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:34.620 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:35.264 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:35.265 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:35.419 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:35.419 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:35.620 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:35.620 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:35.621 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:35.621 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:36.221 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:36,220 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
2025-07-15 18:30:36.292 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:36.292 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:36.420 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:36.420 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:36.622 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:36.622 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:36.623 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:36.623 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:37.305 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:37.306 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:37.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:37.422 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:37.527 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:37.527 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:37.623 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:37.624 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:38.307 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:38.308 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:38.404 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:38.404 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:38.423 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:38.423 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:38.625 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:38.625 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:39.283 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:39.283 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:39.309 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:39.309 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:39.424 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:39.425 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:39.627 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:39.628 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:40.285 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:40.285 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:40.311 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:40.312 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:40.426 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:40.426 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:40.628 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:40.629 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:41.286 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:41.286 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:41.312 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:41.312 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:41.428 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:41.428 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:41.606 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:41.606 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:41.948 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:41,947 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
2025-07-15 18:30:42.287 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:42.288 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:42.313 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:42.314 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:42.430 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:42.430 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:42.469 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:42,468 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
2025-07-15 18:30:42.615 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:42.615 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:43.088 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:43,087 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_893662, Site name: null
2025-07-15 18:30:43.216 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:43.216 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:43.314 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:43.315 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:43.431 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:43.432 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:43.455 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:43,453 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
2025-07-15 18:30:43.477 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:43,476 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
2025-07-15 18:30:43.616 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:43.617 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:44.249 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:44.249 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:44.317 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:44.317 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:44.432 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:44.432 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:44.617 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:44.617 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:45.249 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:45.249 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:45.318 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:45.319 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:45.433 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:45.433 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:45.520 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:45.520 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:45.892 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:45,891 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
2025-07-15 18:30:46.250 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:46.251 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:46.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:46.319 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:46.435 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:46.435 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:46.526 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:46.526 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:47.251 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:47.251 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:47.321 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:47.322 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:47.396 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:47.396 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:47.527 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:47.528 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:48.252 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:48.253 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:48.346 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:48.346 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:48.407 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:48.407 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:48.529 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:48.529 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:49.253 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:49.253 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:49.331 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:49.331 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:49.408 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:49.409 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:49.530 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:49.530 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:50.254 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:50.255 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:50.333 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:50.333 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:50.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:50.423 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:50.433 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:50.433 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:50.448 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:50,447 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
2025-07-15 18:30:50.454 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:50,453 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
2025-07-15 18:30:50.648 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:50,647 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
2025-07-15 18:30:50.968 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:50,966 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 21.099s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
2025-07-15 18:30:50.968 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:50,967 INFO  [io.quarkus] (main) Profile dev activated. 
2025-07-15 18:30:50.968 INFO  [docker-java-stream--1834718396] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:30:50,968 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
2025-07-15 18:30:51.303 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:51.304 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:51.334 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:51.335 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:51.424 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:51.424 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:51.436 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:51.437 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:51.919 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 started in PT34.704157581S
2025-07-15 18:30:51.919 INFO  [main] tc.postgis/postgis:16-3.4 - Creating container for image: postgis/postgis:16-3.4
2025-07-15 18:30:52.012 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 is starting: a66ec36761f9396984d7ad7008f0b6073dc0c3a02e58150f55b411b191105272
2025-07-15 18:30:52.336 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:52.336 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:52.346 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:52.346 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:52.424 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:52.425 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:52.436 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:52.437 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:53.304 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:53.305 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:53.337 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:53.337 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:53.425 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:53.425 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:53.437 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:53.438 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:54.310 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:54.310 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:54.338 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:54.338 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:54.438 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:54.438 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:54.441 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:54.441 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:55.163 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 started in PT3.243487784S
2025-07-15 18:30:55.163 INFO  [main] tc.postgis/postgis:16-3.4 - Container is started (JDBC URL: jdbc:postgresql://localhost:34725/DBBookAnythingPlatform?loggerLevel=OFF)
2025-07-15 18:30:55.165 INFO  [main] o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.SearchNearestLocalizablePlacesIntegrationTest]: SearchNearestLocalizablePlacesIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-07-15 18:30:55.168 INFO  [main] o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.SearchNearestLocalizablePlacesIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:30:55.187 INFO  [main] d.o.d.b.d.SearchNearestLocalizablePlacesIntegrationTest - Starting SearchNearestLocalizablePlacesIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:30:55.187 INFO  [main] d.o.d.b.d.SearchNearestLocalizablePlacesIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:30:55.310 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:55.311 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:55.338 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:55.338 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:55.402 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:30:55.402 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:30:55.412 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.413 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:30:55.420 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 16 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:30:55.424 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:30:55.424 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:30:55.430 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:30:55.439 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 13 ms. Found 8 JPA repository interfaces.
2025-07-15 18:30:55.441 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:55.441 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:55.442 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:55.442 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:55.543 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:30:55.565 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@244a0aa5
2025-07-15 18:30:55.565 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:30:55.576 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:30:55.618 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:30:55.624 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:30:55.634 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:30:55.650 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:30:55.652 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:30:55.653 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:30:55.653 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:30:55.682 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:30:55.685 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:30:55.686 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:30:55.693 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:30:55.693 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:30:55.703 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:30:55.704 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:30:55.763 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:30:55.793 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:30:55.794 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@7317984a] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:30:55.829 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:30:55.830 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:30:55.834 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:30:56.339 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:56.339 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:56.354 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:56.354 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:56.441 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:56.448 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:56.453 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:56.453 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:56.597 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:30:56.716 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:30:56.716 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:30:56.717 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 1 ms
2025-07-15 18:30:56.733 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34721]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-23
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:30:56.734 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:30:56.737 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:30:56.737 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:30:56.737 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597056737
2025-07-15 18:30:56.738 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:30:56.741 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34721]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-24
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:30:56.742 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:30:56.744 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:30:56.744 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:30:56.744 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597056744
2025-07-15 18:30:56.746 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:30:56.747 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34721]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-25
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:30:56.747 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:30:56.750 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:30:56.750 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:30:56.750 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597056750
2025-07-15 18:30:56.752 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:30:56.754 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34721]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-26
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:30:56.754 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:30:56.757 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:30:56.757 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:30:56.757 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597056757
2025-07-15 18:30:56.759 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:30:56.760 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:30:56.827 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:30:56.830 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.830 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.830 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.830 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Cluster ID: DeSaIIRCQbC26_MC4C8o7Q
2025-07-15 18:30:56.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Cluster ID: DeSaIIRCQbC26_MC4C8o7Q
2025-07-15 18:30:56.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Cluster ID: DeSaIIRCQbC26_MC4C8o7Q
2025-07-15 18:30:56.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Cluster ID: DeSaIIRCQbC26_MC4C8o7Q
2025-07-15 18:30:56.832 INFO  [main] d.o.d.b.d.SearchNearestLocalizablePlacesIntegrationTest - Started SearchNearestLocalizablePlacesIntegrationTest in 1.66 seconds (process running for 387.246)
2025-07-15 18:30:56.948 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.954 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:56.959 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:30:57.165 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34721 (id: 2147483646 rack: null)
2025-07-15 18:30:57.165 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34721 (id: 2147483646 rack: null)
2025-07-15 18:30:57.165 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:30:57.166 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:30:57.184 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34721 (id: 2147483646 rack: null)
2025-07-15 18:30:57.186 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:30:57.188 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Discovered group coordinator localhost:34721 (id: 2147483646 rack: null)
2025-07-15 18:30:57.189 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-24-5375f49e-d0c7-4e7d-b9fc-a034ba940f20
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-26-6e87ca9b-e599-4b85-a7be-32530d4003f1
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-23-3aae739c-6aeb-47c5-ab34-8c1dc3d609ff
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-25-f8eaecd9-136b-458c-b1e8-8204e63f36e8
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:30:57.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:30:57.231 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-26-6e87ca9b-e599-4b85-a7be-32530d4003f1', protocol='range'}
2025-07-15 18:30:57.231 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-26-6e87ca9b-e599-4b85-a7be-32530d4003f1=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:30:57.234 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-25-f8eaecd9-136b-458c-b1e8-8204e63f36e8', protocol='range'}
2025-07-15 18:30:57.234 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-25-f8eaecd9-136b-458c-b1e8-8204e63f36e8=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:30:57.235 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-23-3aae739c-6aeb-47c5-ab34-8c1dc3d609ff', protocol='range'}
2025-07-15 18:30:57.235 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-23-3aae739c-6aeb-47c5-ab34-8c1dc3d609ff=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
2025-07-15 18:30:57.236 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-24-5375f49e-d0c7-4e7d-b9fc-a034ba940f20', protocol='range'}
2025-07-15 18:30:57.237 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-24-5375f49e-d0c7-4e7d-b9fc-a034ba940f20=Assignment(partitions=[geojson-upload-topic-0])}
2025-07-15 18:30:57.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-24-5375f49e-d0c7-4e7d-b9fc-a034ba940f20', protocol='range'}
2025-07-15 18:30:57.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-25-f8eaecd9-136b-458c-b1e8-8204e63f36e8', protocol='range'}
2025-07-15 18:30:57.293 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-23-3aae739c-6aeb-47c5-ab34-8c1dc3d609ff', protocol='range'}
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-26-6e87ca9b-e599-4b85-a7be-32530d4003f1', protocol='range'}
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:30:57.294 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:30:57.307 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:30:57.307 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:30:57.307 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:30:57.307 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:30:57.310 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:30:57.310 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:30:57.310 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:30:57.310 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:30:57.324 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34721 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:30:57.324 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34721 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:30:57.324 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34721 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:30:57.324 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34721 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:30:57.341 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:57.341 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:57.352 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:30:57.351 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:30:57.351 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:30:57.351 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:30:57.355 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:57.355 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:30:57.392 INFO  [main] o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [PLAINTEXT://localhost:34721]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = BookAnythingBackendApplication-producer-1
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 52428800
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2025-07-15 18:30:57.393 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:30:57.394 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Instantiated an idempotent producer.
2025-07-15 18:30:57.397 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:30:57.397 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:30:57.397 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597057397
2025-07-15 18:30:57.406 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] org.apache.kafka.clients.Metadata - [Producer clientId=BookAnythingBackendApplication-producer-1] Cluster ID: DeSaIIRCQbC26_MC4C8o7Q
2025-07-15 18:30:57.442 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:57.442 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:57.449 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:57.449 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:57.520 INFO  [kafka-producer-network-thread | BookAnythingBackendApplication-producer-1] o.a.k.c.p.i.TransactionManager - [Producer clientId=BookAnythingBackendApplication-producer-1] ProducerId set to 0 with epoch 0
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:30:57.582 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=d3e7c6e8-7f0b-498a-b025-abc5a20e046b, nome=CD Proximo 0
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.ds_name=? 
    fetch
        first ? rows only
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Documents found in ElasticSearch: 
2025-07-15 18:30:57.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=d3e7c6e8-7f0b-498a-b025-abc5a20e046b, nome=CD Proximo 0
2025-07-15 18:30:57.816 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=38da1061-c904-4d5c-ae59-026bdc44ee69, nome=CD Proximo 1
2025-07-15 18:30:57.861 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=38da1061-c904-4d5c-ae59-026bdc44ee69, nome=CD Proximo 1
2025-07-15 18:30:57.868 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=7ce80933-e06f-4527-93a7-7ed05a198cfa, nome=CD Proximo 2
2025-07-15 18:30:57.956 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=7ce80933-e06f-4527-93a7-7ed05a198cfa, nome=CD Proximo 2
2025-07-15 18:30:57.958 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Received one Event about the creation of a new Localizable Place: id=ee66da7c-9628-4363-9a83-c361dec31b23, nome=CD Longe
Documents found in ElasticSearch: d3e7c6e8-7f0b-498a-b025-abc5a20e046b, 38da1061-c904-4d5c-ae59-026bdc44ee69
2025-07-15 18:30:58.025 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] d.o.d.b.d.i.a.i.m.k.LocalizablePlaceCreatedKafkaConsumer - Localizable Place was indexed in ElasticSearch: id=ee66da7c-9628-4363-9a83-c361dec31b23, nome=CD Longe
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-26-6e87ca9b-e599-4b85-a7be-32530d4003f1 sending LeaveGroup request to coordinator localhost:34721 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-25-f8eaecd9-136b-458c-b1e8-8204e63f36e8 sending LeaveGroup request to coordinator localhost:34721 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-23-3aae739c-6aeb-47c5-ab34-8c1dc3d609ff sending LeaveGroup request to coordinator localhost:34721 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Member consumer-geojson-processor-24-5375f49e-d0c7-4e7d-b9fc-a034ba940f20 sending LeaveGroup request to coordinator localhost:34721 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-25, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-26, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-23, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-24, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:30:58.342 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:58.342 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:58.357 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:58.357 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:58.375 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:30:58.375 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:30:58.375 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:30:58.375 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:30:58.377 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-25 unregistered
2025-07-15 18:30:58.378 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:30:58.405 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:30:58.405 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:30:58.405 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:30:58.405 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:30:58.416 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:30:58.416 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:30:58.416 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:30:58.416 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:30:58.416 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:30:58.417 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:30:58.417 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:30:58.417 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:30:58.417 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-23 unregistered
2025-07-15 18:30:58.418 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:30:58.424 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-24 unregistered
2025-07-15 18:30:58.425 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:30:58.425 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-26 unregistered
2025-07-15 18:30:58.425 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:30:58.426 INFO  [main] o.a.k.clients.producer.KafkaProducer - [Producer clientId=BookAnythingBackendApplication-producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2025-07-15 18:30:58.431 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:30:58.431 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:30:58.431 INFO  [main] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:30:58.431 INFO  [main] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:30:58.431 INFO  [main] o.a.kafka.common.utils.AppInfoParser - App info kafka.producer for BookAnythingBackendApplication-producer-1 unregistered
2025-07-15 18:30:58.436 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:30:58.437 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:30:58.442 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.
2025-07-15 18:30:58.452 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:58.452 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:58.465 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:58.465 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:59.343 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:30:59.344 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:59.358 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:30:59.358 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:59.453 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:30:59.453 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:30:59.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:30:59.469 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 74.80 s -- in de.org.dexterity.bookanything.dom01geolocation.SearchNearestLocalizablePlacesIntegrationTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.SynchronizeEndpointIntegrationTest
2025-07-15 18:30:59.802 INFO  [main] tc.elasticsearch:8.14.0 - Creating container for image: elasticsearch:8.14.0
2025-07-15 18:30:59.877 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 is starting: ec0a688b6607a4a3846b3f684b89de17f3a7ade07dd94e74e3ef40f0b32d55d2
2025-07-15 18:31:00.344 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:00.344 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:00.359 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:00.359 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:00.453 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:00.454 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:00.506 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:00.506 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:01.347 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:01.348 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:01.360 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:01.360 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:01.453 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:01.454 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:01.507 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:01.507 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:02.347 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:02.348 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:02.361 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:02.361 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:02.454 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:02.454 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:02.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:02.508 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:03.372 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:03.372 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:03.384 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:03.384 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:03.455 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:03.455 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:03.473 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:03.473 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:04.372 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:04.373 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:04.386 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:04.388 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:04.455 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:04.456 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:04.477 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:04.477 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:05.276 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:05.276 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:05.411 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:05.411 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:05.455 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:05.456 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:05.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:05.478 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:06.181 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:06.182 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:06.411 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:06.412 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:06.457 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:06.457 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:06.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:06.479 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:07.183 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:07.183 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:07.413 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:07.414 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:07.460 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:07.461 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:07.478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:07.479 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:08.183 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:08.183 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:08.414 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:08.414 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:08.461 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:08.461 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:08.477 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:08.477 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:09.184 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:09.184 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:09.343 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:09.343 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:09.462 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:09.462 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:09.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:09.482 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:10.185 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:10.185 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:10.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:10.349 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:10.463 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:10.464 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:10.482 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:10.482 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:11.189 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:11.189 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:11.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:11.350 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:11.463 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:11.463 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:11.483 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:11.483 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:12.190 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:12.191 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:12.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:12.350 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:12.463 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:12.463 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:12.498 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:12.498 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:13.191 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:13.191 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:13.318 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:13.318 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:13.464 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:13.465 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:13.499 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:13.499 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:14.194 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:14.197 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:14.223 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:14.224 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:14.368 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:14.368 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:14.499 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:14.500 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:15.165 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:15.165 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:15.230 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:15.231 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:15.369 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:15.369 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:15.500 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:15.500 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:16.120 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:16.121 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:16.198 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:16.199 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:16.370 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:16.370 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:16.495 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@2847fd39 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:16.501 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:16.502 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:16.802 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@697af702 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:17.123 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:17.123 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:17.203 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:17.203 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:17.372 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:17.373 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:17.449 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@5fefc31 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:17.518 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:17.519 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:18.126 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:18.127 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:18.204 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:18.204 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:18.374 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:18.374 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:18.519 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:18.519 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:19.127 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:19.127 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:19.205 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:19.205 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:19.374 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:19.375 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:19.520 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:19.520 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:20.128 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:20.128 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:20.206 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:20.206 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:20.375 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:20.376 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:20.521 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:20.522 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:21.130 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:21.130 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:21.207 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:21.208 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:21.377 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:21.377 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:21.521 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:21.522 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:22.134 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:22.134 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:22.193 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:22.194 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:22.281 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:22.281 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:22.522 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:22.523 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:23.128 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:23.128 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:23.134 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:23.134 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:23.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:23.319 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:23.413 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:23.414 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:23.831 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 started in PT24.029057088S
2025-07-15 18:31:23.831 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Creating container for image: confluentinc/cp-kafka:7.6.0
2025-07-15 18:31:23.910 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 is starting: 3c3f553b83914d27ef9041e2bfe3057c6af6b374af588508dcadab6d306af2f5
2025-07-15 18:31:24.041 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:24.041 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:24.130 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:24.131 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:24.318 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:24.318 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:24.320 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:24.320 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:24.991 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:24.991 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:25.131 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:25.131 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:25.223 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:25.223 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:25.319 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:25.319 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:25.992 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:25.993 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:26.131 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:26.131 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:26.179 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:26.180 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:26.320 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:26.321 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:26.999 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:26.999 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:27.112 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:27.112 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:27.132 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:27.132 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:27.322 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:27.322 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:27.999 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:27.999 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:28.086 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@4fe0196b (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:28.130 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:28.130 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:28.132 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:28.133 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:28.323 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:28.324 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:29.003 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:29.003 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:29.066 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:29.066 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:29.131 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:29.131 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:29.199 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@37292b4d (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:29.324 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:29.324 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:30.004 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:30.004 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:30.074 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:30.074 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:30.111 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:30.111 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:30.325 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:30.325 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:30.967 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@955084d (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:31.005 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:31.006 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:31.021 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 started in PT7.190069914S
2025-07-15 18:31:31.023 INFO  [main] tc.keycloak/keycloak:26.3.1 - Creating container for image: keycloak/keycloak:26.3.1
2025-07-15 18:31:31.075 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:31.075 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:31.135 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:31.136 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:31.187 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 is starting: d29ed8a45f245e5b13b54e359a40ac0dafefbfbaaa0b80a926d1085244e1066b
2025-07-15 18:31:31.228 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:31.228 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:31.470 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
2025-07-15 18:31:31.480 INFO  [main] o.t.c.wait.strategy.HttpWaitStrategy - /sad_goldberg: Waiting for 120 seconds for URL: http://localhost:34732/health/started (where port 34732 maps to container port 9000)
2025-07-15 18:31:32.007 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:32.007 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:32.076 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:32.076 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:32.136 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:32.136 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:32.229 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:32.229 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:32.379 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@46b1734d (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:32.468 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
2025-07-15 18:31:33.016 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:33.016 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:33.120 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:33.120 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:33.137 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:33.137 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:33.231 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:33.231 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:34.018 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:34.019 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:34.109 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:34.109 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:34.138 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:34.138 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:34.231 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:34.232 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:34.668 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@5220bd43 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:34.910 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:34.910 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:35.064 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:35.065 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:35.146 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:35.146 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:35.232 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:35.233 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:35.281 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@2c2d8709 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:35.925 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:35.926 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:36.040 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:36.040 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:36.066 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:36.067 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:36.233 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:36.233 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:36.737 WARN  [Hikari:housekeeper] com.zaxxer.hikari.pool.PoolBase - Hikari - Failed to validate connection org.postgresql.jdbc.PgConnection@d1bf5a1 (This connection has been closed.). Possibly consider using a shorter maxLifetime value.
2025-07-15 18:31:36.929 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:36.930 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:37.050 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:37.051 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:37.071 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:37.072 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:37.136 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:37.136 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:37.956 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:37.956 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:38.051 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:38.052 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:38.073 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:38.073 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:38.172 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:38.172 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:38.999 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:38.999 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:39.052 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:39.052 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:39.115 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:39.115 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:39.173 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:39.173 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:40.000 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:40.001 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:40.053 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:40.054 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:40.116 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:40.116 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:40.172 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:40.172 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:40.958 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:40.958 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:41.004 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:41.005 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:41.116 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:41.116 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:41.173 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:41.173 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:41.959 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:41.960 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:42.005 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:42.005 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:42.116 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:42.116 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:42.173 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:42.174 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:42.925 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:42,923 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 9655ms
2025-07-15 18:31:42.959 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:42.960 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:43.005 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:43.005 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:43.113 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:43.113 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:43.116 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:43.117 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:43.907 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:43.908 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:43.960 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:43.960 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:43.977 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: Running the server in development mode. DO NOT use this configuration in production.
2025-07-15 18:31:44.016 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:44.016 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:44.117 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:44.117 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:44.887 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:44.888 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:44.917 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:44.917 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:44.961 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:44.961 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:45.118 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:45.119 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:45.820 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:45.820 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:45.888 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:45.888 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:45.962 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:45.963 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:46.118 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:46.118 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:46.821 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:46.821 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:46.890 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:46.890 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:46.963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:46.963 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:47.120 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:47.120 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:47.822 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:47.822 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:47.857 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:47.857 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:47.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:47.964 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:48.120 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:48.120 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:48.824 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:48.824 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:48.906 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:48.907 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:48.965 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:48.965 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:49.121 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:49.122 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:49.218 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:49,216 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
2025-07-15 18:31:49.825 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:49.825 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:49.907 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:49.907 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:49.965 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:49.966 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:50.126 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:50.126 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:50.805 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:50.805 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:50.827 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:50.827 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:51.012 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:51.013 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:51.128 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:51.128 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:51.816 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:51.816 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:51.828 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:51.829 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:52.013 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:52.014 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:52.147 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:52.147 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:52.732 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:52.732 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:52.804 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:52.804 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:53.014 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:53.014 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:53.148 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:53.148 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:53.363 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:53,361 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
2025-07-15 18:31:53.632 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:53,631 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
2025-07-15 18:31:53.767 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:53.767 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:53.781 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:53.781 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:54.014 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:54.014 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:54.032 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:54,031 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_948615, Site name: null
2025-07-15 18:31:54.148 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:54.149 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:54.295 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:54,295 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
2025-07-15 18:31:54.305 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:54,304 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
2025-07-15 18:31:54.672 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:54.673 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:54.725 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:54.725 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:55.041 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:55.041 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:55.149 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:55.149 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:55.673 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:55.673 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:55.726 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:55.726 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:55.909 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:55,908 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
2025-07-15 18:31:56.043 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:56.043 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:56.151 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:56.151 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:56.641 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:56.641 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:56.727 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:56.728 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:57.044 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:57.044 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:57.152 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:57.152 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:57.642 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:57.642 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:57.728 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:57.728 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:58.044 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:58.045 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:58.107 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:58.107 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:58.559 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:58.559 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:58.678 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:58,670 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
2025-07-15 18:31:58.678 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:58,675 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
2025-07-15 18:31:58.729 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:58.729 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:58.824 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:58,823 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
2025-07-15 18:31:59.045 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:31:59.045 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:59.052 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:59,051 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 15.938s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
2025-07-15 18:31:59.052 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:59,052 INFO  [io.quarkus] (main) Profile dev activated. 
2025-07-15 18:31:59.052 INFO  [docker-java-stream-1360764341] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:31:59,052 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
2025-07-15 18:31:59.111 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:31:59.111 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:59.513 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:31:59.513 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:31:59.647 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 started in PT28.623708648S
2025-07-15 18:31:59.647 INFO  [main] tc.postgis/postgis:16-3.4 - Creating container for image: postgis/postgis:16-3.4
2025-07-15 18:31:59.706 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 is starting: 4aa71bc6d17ee34d7ea5ddf9f8b30f20b2ae81e43a4824a5aa4778ca1383a9c7
2025-07-15 18:31:59.729 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:31:59.730 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:00.046 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:00.046 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:00.112 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:00.112 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:00.513 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:00.514 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:00.731 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:00.731 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:01.047 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:01.054 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:01.113 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:01.113 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:01.514 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:01.514 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:01.732 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:01.732 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:02.035 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:02.035 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:02.048 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:02.048 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:02.355 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 started in PT2.707963412S
2025-07-15 18:32:02.355 INFO  [main] tc.postgis/postgis:16-3.4 - Container is started (JDBC URL: jdbc:postgresql://localhost:34733/DBBookAnythingPlatform?loggerLevel=OFF)
2025-07-15 18:32:02.358 INFO  [main] o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.SynchronizeEndpointIntegrationTest]: SynchronizeEndpointIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-07-15 18:32:02.361 INFO  [main] o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.SynchronizeEndpointIntegrationTest

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:32:02.390 INFO  [main] d.o.d.b.d.SynchronizeEndpointIntegrationTest - Starting SynchronizeEndpointIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:32:02.390 INFO  [main] d.o.d.b.d.SynchronizeEndpointIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:32:02.553 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:02.553 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:02.642 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:32:02.643 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:32:02.650 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.651 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:32:02.657 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 13 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:32:02.661 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:32:02.661 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:32:02.667 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:32:02.679 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 17 ms. Found 8 JPA repository interfaces.
2025-07-15 18:32:02.698 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:02.698 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:02.777 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:32:02.796 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@67b22ea3
2025-07-15 18:32:02.796 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:32:02.806 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:32:02.833 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:32:02.839 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:32:02.848 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:32:02.863 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:32:02.863 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:32:02.864 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:32:02.864 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:32:02.882 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:32:02.885 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:32:02.886 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:32:02.890 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:32:02.890 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:32:02.898 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:32:02.899 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:32:02.961 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:32:02.985 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:32:02.985 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@6c40ba9c] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
2025-07-15 18:32:03.001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:03.001 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:32:03.019 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:32:03.019 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:32:03.026 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:32:03.084 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:03.085 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:03.554 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:03.554 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:03.702 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:03.702 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:03.903 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:32:04.002 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:04.003 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:04.084 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:04.085 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:04.142 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:32:04.142 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:32:04.144 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 1 ms
2025-07-15 18:32:04.164 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34729]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-27
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:32:04.164 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:32:04.167 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:32:04.167 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:32:04.167 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597124167
2025-07-15 18:32:04.168 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:32:04.170 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34729]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-28
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:32:04.170 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:32:04.176 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:32:04.176 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:32:04.176 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597124176
2025-07-15 18:32:04.179 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:32:04.182 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34729]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-29
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:32:04.182 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:32:04.187 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:32:04.187 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:32:04.187 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597124187
2025-07-15 18:32:04.189 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:32:04.192 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34729]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-30
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:32:04.192 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:32:04.201 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:32:04.201 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:32:04.201 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597124201
2025-07-15 18:32:04.205 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:32:04.206 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:32:04.281 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:32:04.281 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:32:04.281 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:32:04.281 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:32:04.282 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Cluster ID: j8mCxxv3S7ucE622kgmvyQ
2025-07-15 18:32:04.282 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Cluster ID: j8mCxxv3S7ucE622kgmvyQ
2025-07-15 18:32:04.282 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Cluster ID: j8mCxxv3S7ucE622kgmvyQ
2025-07-15 18:32:04.282 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Cluster ID: j8mCxxv3S7ucE622kgmvyQ
2025-07-15 18:32:04.311 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:32:04.318 INFO  [main] d.o.d.b.d.SynchronizeEndpointIntegrationTest - Started SynchronizeEndpointIntegrationTest in 1.953 seconds (process running for 454.732)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.411 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:32:04.411 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:32:04.414 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.438 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:04.491 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.637 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34729 (id: 2147483646 rack: null)
2025-07-15 18:32:04.640 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] (Re-)joining group
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.646 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Discovered group coordinator localhost:34729 (id: 2147483646 rack: null)
2025-07-15 18:32:04.646 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34729 (id: 2147483646 rack: null)
2025-07-15 18:32:04.647 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:32:04.647 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34729 (id: 2147483646 rack: null)
2025-07-15 18:32:04.647 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] (Re-)joining group
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.647 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] (Re-)joining group
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.665 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-27-ac22df9c-4b6f-4e9a-97d7-2a91fbe9350d
2025-07-15 18:32:04.665 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] (Re-)joining group
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-29-7b940d57-9f1e-4af4-93ff-c80c52544d63
2025-07-15 18:32:04.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-30-d0c74135-caa5-4aef-9cd9-e5a2e1617391
2025-07-15 18:32:04.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-28-4424b20d-18f3-4b06-8a17-0601fafab133
2025-07-15 18:32:04.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:32:04.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:32:04.670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] (Re-)joining group
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.696 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-28-4424b20d-18f3-4b06-8a17-0601fafab133', protocol='range'}
2025-07-15 18:32:04.696 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-28-4424b20d-18f3-4b06-8a17-0601fafab133=Assignment(partitions=[geojson-upload-topic-0])}
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.699 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-29-7b940d57-9f1e-4af4-93ff-c80c52544d63', protocol='range'}
2025-07-15 18:32:04.699 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-29-7b940d57-9f1e-4af4-93ff-c80c52544d63=Assignment(partitions=[localizable-place-created-topic-0])}
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.700 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-27-ac22df9c-4b6f-4e9a-97d7-2a91fbe9350d', protocol='range'}
2025-07-15 18:32:04.701 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-27-ac22df9c-4b6f-4e9a-97d7-2a91fbe9350d=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.703 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-30-d0c74135-caa5-4aef-9cd9-e5a2e1617391', protocol='range'}
2025-07-15 18:32:04.703 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:04.704 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-30-d0c74135-caa5-4aef-9cd9-e5a2e1617391=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:32:04.704 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-30-d0c74135-caa5-4aef-9cd9-e5a2e1617391', protocol='range'}
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-28-4424b20d-18f3-4b06-8a17-0601fafab133', protocol='range'}
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-29-7b940d57-9f1e-4af4-93ff-c80c52544d63', protocol='range'}
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-27-ac22df9c-4b6f-4e9a-97d7-2a91fbe9350d', protocol='range'}
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:32:04.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.805 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:32:04.805 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:32:04.806 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:32:04.805 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:32:04.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:32:04.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:32:04.809 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
2025-07-15 18:32:04.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34729 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:32:04.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34729 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:32:04.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34729 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:32:04.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34729 (id: 1 rack: null)], epoch=0}}.
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
2025-07-15 18:32:04.881 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:32:04.881 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:32:04.881 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:32:04.882 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0 
    where
        lpje1_0.id=?
Hibernate: 
    insert 
    into
        tb_localizable_place
        (ge_location, ds_name, id) 
    values
        (?, ?, ?)
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0
2025-07-15 18:32:04.951 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:04.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:05.085 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:05.086 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:05.491 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:05.492 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:05.705 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:05.705 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:05.953 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:05.953 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:05.990 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:05.990 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Synchronization done: {before.entries-in-queryable-repository.count=0, before.records-in-writeable-repository.count=100, after.entries-in-queryable-repository.count=100}
Hibernate: 
    select
        lpje1_0.id,
        lpje1_0.ge_location,
        lpje1_0.ds_name 
    from
        tb_localizable_place lpje1_0
2025-07-15 18:32:06.494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:06.494 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_localizable_place 
    where
        id=?
2025-07-15 18:32:06.706 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:06.706 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:06.845 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:32:06.846 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:32:06.846 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:32:06.845 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:32:06.845 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:32:06.846 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:32:06.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Member consumer-geojson-processor-28-4424b20d-18f3-4b06-8a17-0601fafab133 sending LeaveGroup request to coordinator localhost:34729 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:32:06.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:32:06.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-29-7b940d57-9f1e-4af4-93ff-c80c52544d63 sending LeaveGroup request to coordinator localhost:34729 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:32:06.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-27-ac22df9c-4b6f-4e9a-97d7-2a91fbe9350d sending LeaveGroup request to coordinator localhost:34729 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:32:06.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:32:06.847 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-30-d0c74135-caa5-4aef-9cd9-e5a2e1617391 sending LeaveGroup request to coordinator localhost:34729 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.848 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-30, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-27, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-28, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.850 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.850 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-29, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:32:06.954 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:06.955 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:06.998 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:06.999 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:07.061 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:32:07.061 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:32:07.061 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:32:07.061 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:32:07.067 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-30 unregistered
2025-07-15 18:32:07.068 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:32:07.073 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:32:07.073 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:32:07.073 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:32:07.073 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:32:07.074 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:32:07.074 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:32:07.074 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:32:07.074 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:32:07.082 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-28 unregistered
2025-07-15 18:32:07.082 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-29 unregistered
2025-07-15 18:32:07.083 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:32:07.084 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:32:07.087 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:32:07.087 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:32:07.087 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:32:07.088 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:32:07.095 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-27 unregistered
2025-07-15 18:32:07.097 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:32:07.105 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:32:07.106 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:32:07.110 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.
2025-07-15 18:32:07.495 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:07.495 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:07.707 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:07.707 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:07.815 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:07.815 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:07.815 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:32:07.832 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:07.832 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:07.832 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:32:08.377 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:08.377 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:08.549 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:08.549 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:08.701 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:08.701 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 68.97 s -- in de.org.dexterity.bookanything.dom01geolocation.SynchronizeEndpointIntegrationTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.application.services.GeoLocationCRUDServiceTest
OpenJDK 64-Bit Server VM warning: Sharing is only supported for boot loader classes because bootstrap classpath has been appended
2025-07-15 18:32:08.852 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:08.852 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:09.404 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:09.405 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:09.580 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:09.580 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:09.581 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:09.581 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:10.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:10.029 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:10.545 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:10.547 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:10.587 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:10.599 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:10.606 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:10.614 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:11.218 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:11.220 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:11.705 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:11.705 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:11.705 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:11.706 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:11.706 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:11.706 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:12.220 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:12.221 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:12.743 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:12.743 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:12.743 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:12.743 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:12.744 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:12.744 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:13.143 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:13.145 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.772 s -- in de.org.dexterity.bookanything.dom01geolocation.application.services.GeoLocationCRUDServiceTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.AddressControllerTest
2025-07-15 18:32:13.822 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:13.822 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:13.822 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:13.822 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:13.822 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:13.822 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:14.013 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:14.013 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:14.863 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:14.864 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:14.863 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:14.864 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:14.865 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:14.866 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:15.015 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:15.016 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.676 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.AddressControllerTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.GeoLocationControllerIntegrationTest
2025-07-15 18:32:15.300 INFO  [main] tc.elasticsearch:8.14.0 - Creating container for image: elasticsearch:8.14.0
2025-07-15 18:32:15.469 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 is starting: b4ef96d8afb802eb626fc6698e4244e3d20efddec8716cc81aab47899067eb49
2025-07-15 18:32:15.864 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:15.864 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:15.864 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:15.866 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:15.867 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:15.867 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:16.018 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:16.020 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:16.719 WARN  [Hikari:connection-adder] com.zaxxer.hikari.pool.PoolBase - Hikari - Pool is empty, failed to create/setup connection (c7fc5518-a7cb-4f67-9045-5e8cb650331d)
org.postgresql.util.PSQLException: Connection to localhost:34717 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:373)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:57)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:277)
	at org.postgresql.Driver.makeConnection(Driver.java:448)
	at org.postgresql.Driver.connect(Driver.java:298)
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:139)
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:368)
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:205)
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:483)
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:747)
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:726)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:592)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:751)
	at org.postgresql.core.PGStream.createSocket(PGStream.java:261)
	at org.postgresql.core.PGStream.<init>(PGStream.java:122)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:146)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:289)
	... 14 common frames omitted
2025-07-15 18:32:16.865 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:16.866 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:16.866 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:16.866 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:16.868 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:16.869 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:17.021 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:17.022 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:17.836 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:17.836 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:17.837 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:32:17.945 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:17.946 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:17.946 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:17.946 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:18.026 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:18.027 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:18.838 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:18.838 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:18.947 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:18.947 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:18.951 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:18.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:19.027 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:19.028 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:19.839 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:19.840 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:19.950 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:19.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:19.952 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:19.952 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:20.028 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:20.029 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:20.889 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:20.889 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:20.951 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:20.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:20.953 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:20.953 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:21.030 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:21.030 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:21.842 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:21.842 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:21.891 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:21.891 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:21.993 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:21.994 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:22.013 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:22.014 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:22.866 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:22.867 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:22.867 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:32:22.923 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:22.924 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:22.926 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:22.926 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:22.988 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:22.989 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:23.867 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:23.867 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:23.893 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:23.894 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:23.927 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:23.928 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:23.932 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:23.933 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:24.868 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:24.869 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:24.895 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:24.896 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:24.928 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:24.929 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:24.933 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:24.934 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:25.824 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:25.824 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:25.896 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:25.896 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:25.931 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:25.932 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:25.936 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:25.937 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:26.782 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:26.783 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:26.842 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:26.843 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:26.897 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:26.897 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:26.932 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:26.932 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:27.700 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:27.700 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:27.784 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:27.784 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:27.839 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:27.839 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:27.839 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:32:27.913 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:27.913 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:28.702 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:28.702 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:28.786 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:28.786 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:28.850 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:28.850 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:28.915 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:28.916 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:29.703 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:29.703 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:29.789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:29.789 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:29.840 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:29.857 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:29.917 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:29.919 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:30.715 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:30.715 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:30.791 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:30.791 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:30.842 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:30.842 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:30.919 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:30.919 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:31.716 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:31.716 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:31.791 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:31.792 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:31.843 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:31.843 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:31.962 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:31.963 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:32.717 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:32.720 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:32.792 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:32.792 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:32.930 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:32.930 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:32.987 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:32.987 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:33.653 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:33.653 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:33.819 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:33.820 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:33.931 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:33.932 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:33.988 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:33.988 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:34.654 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:34.654 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:34.820 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:34.820 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:34.932 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:34.933 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:35.022 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:35.022 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:35.655 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:35.656 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:35.863 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:35.863 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:35.933 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:35.933 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:36.024 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:36.024 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:36.656 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:36.656 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:36.792 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:36.793 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:36.955 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:36.955 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:37.025 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:37.026 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:37.658 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:37.658 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:37.820 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:37.820 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:37.847 INFO  [main] tc.elasticsearch:8.14.0 - Container elasticsearch:8.14.0 started in PT22.546879481S
2025-07-15 18:32:37.848 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Creating container for image: confluentinc/cp-kafka:7.6.0
2025-07-15 18:32:37.926 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 is starting: 4383a9bec4e3abdcb0e7d220526985d277326b1ede4b62851b10497a10571aab
2025-07-15 18:32:38.009 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:38.009 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:38.027 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:38.028 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:38.659 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:38.660 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:38.822 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:38.824 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:39.029 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:39.029 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:39.033 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:39.033 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:39.660 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:39.660 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:39.823 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:39.823 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:39.964 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:39.964 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:40.058 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:40.059 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:40.661 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:40.661 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:40.827 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:40.827 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:40.990 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:40.991 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:41.058 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:41.058 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:41.662 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:41.662 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:41.828 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:41.828 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:41.894 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:41.894 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:42.059 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:42.059 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:42.663 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:42.663 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:42.744 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:42.745 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:42.829 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:42.829 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:43.023 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:43.023 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:43.663 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:43.664 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:43.745 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:43.745 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:43.863 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:43.863 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:44.028 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:44.029 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:44.209 INFO  [main] tc.confluentinc/cp-kafka:7.6.0 - Container confluentinc/cp-kafka:7.6.0 started in PT6.361814189S
2025-07-15 18:32:44.211 INFO  [main] tc.keycloak/keycloak:26.3.1 - Creating container for image: keycloak/keycloak:26.3.1
2025-07-15 18:32:44.367 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 is starting: 9544c1650e02107313f98bf84c156d45b9b9d1cab5b52164f27cef20c0590f00
2025-07-15 18:32:44.638 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: JAVA_OPTS_KC_HEAP already set in environment; overriding default settings
2025-07-15 18:32:44.644 INFO  [main] o.t.c.wait.strategy.HttpWaitStrategy - /distracted_poitras: Waiting for 120 seconds for URL: http://localhost:34741/health/started (where port 34741 maps to container port 9000)
2025-07-15 18:32:44.664 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:44.664 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:44.746 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:44.746 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:44.863 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:44.864 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:45.074 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:45.074 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:45.588 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: Updating the configuration and installing your custom providers, if any. Please wait.
2025-07-15 18:32:45.601 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:45.601 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:45.663 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:45.663 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:45.864 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:45.864 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:46.075 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:46.075 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:46.557 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:46.558 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:46.573 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:46.573 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:46.867 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:46.867 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:46.980 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:46.980 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:47.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:47.566 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:47.575 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:47.575 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:47.868 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:47.868 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:47.981 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:47.981 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:48.568 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:48.568 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:48.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:48.577 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:48.777 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:48.777 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:48.981 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:48.982 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:49.578 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:49.578 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:49.614 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:49.614 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:49.635 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:49.636 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:49.982 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:49.982 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:50.586 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:50.587 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:50.616 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:50.616 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:50.637 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:50.637 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:50.870 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:50.870 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:51.587 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:51.587 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:51.617 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:51.618 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:51.638 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:51.639 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:51.910 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:51.910 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:52.589 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:52.589 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:52.640 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:52.640 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:52.640 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:52.640 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:52.927 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:52.927 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:53.590 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:53.590 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:53.642 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:53.642 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:53.642 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:53.642 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:53.928 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:53.928 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:54.544 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:54.544 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:54.592 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:54.592 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:54.641 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:54.641 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:54.929 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:54.929 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:55.495 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:55.495 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:55.496 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:55.496 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:55.530 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:32:55,529 INFO  [io.quarkus.deployment.QuarkusAugmentor] (main) Quarkus augmentation completed in 8903ms
2025-07-15 18:32:55.564 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:55.564 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:55.930 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:55.931 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:56.468 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: Running the server in development mode. DO NOT use this configuration in production.
2025-07-15 18:32:56.495 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:56.495 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:56.495 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:56.496 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:56.496 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:56.496 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:56.931 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:56.931 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:57.397 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:57.398 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:57.495 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:57.496 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:57.497 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:57.497 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:57.949 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:57.949 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:58.344 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:58.344 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:58.498 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:58.498 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:58.530 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:58.530 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:58.950 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:58.950 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:59.367 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:32:59.367 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:59.499 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:32:59.499 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:59.531 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:32:59.531 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:32:59.951 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:32:59.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:00.368 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:00.368 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:00.499 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:00.499 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:00.532 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:00.532 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:00.951 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:00.951 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:01.369 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:01.369 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:01.402 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:01.402 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:01.411 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:01,409 INFO  [org.keycloak.quarkus.runtime.storage.database.liquibase.QuarkusJpaUpdaterProvider] (main) Initializing database schema. Using changelog META-INF/jpa-changelog-master.xml
2025-07-15 18:33:01.503 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:01.503 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:01.953 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:01.953 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:02.355 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:02.355 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:02.370 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:02.370 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:02.506 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:02.507 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:02.986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:02.986 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:03.356 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:03.357 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:03.370 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:03.371 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:03.507 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:03.507 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:03.993 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:03.994 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:04.371 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:04.371 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:04.395 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:04.395 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:04.508 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:04.508 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:04.994 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:04.995 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:05.281 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:05,280 INFO  [org.keycloak.spi.infinispan.impl.embedded.JGroupsConfigurator] (main) JGroups JDBC_PING discovery enabled.
2025-07-15 18:33:05.372 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:05.372 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:05.396 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:05.396 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:05.509 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:05.509 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:05.577 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:05,575 INFO  [org.infinispan.CONTAINER] (main) ISPN000556: Starting user marshaller 'org.infinispan.commons.marshall.ImmutableProtoStreamMarshaller'
2025-07-15 18:33:05.995 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:05.995 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:06.117 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:06,116 INFO  [org.keycloak.connections.infinispan.DefaultInfinispanConnectionProviderFactory] (main) Node name: node_655680, Site name: null
2025-07-15 18:33:06.373 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:06.374 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:06.385 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:06,383 INFO  [org.keycloak.exportimport.dir.DirImportProvider] (main) Importing from directory /opt/keycloak/bin/../data/import
2025-07-15 18:33:06.397 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:06,396 INFO  [org.keycloak.services] (main) KC-SERVICES0050: Initializing master realm
2025-07-15 18:33:06.399 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:06.399 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:06.511 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:06.511 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:06.996 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:06.997 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:07.251 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:07.251 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:07.399 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:07.400 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:07.512 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:07.513 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:07.976 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:07,975 INFO  [org.keycloak.services] (main) KC-SERVICES0030: Full model import requested. Strategy: IGNORE_EXISTING
2025-07-15 18:33:07.996 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:07.997 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:08.144 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:08.144 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:08.399 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:08.400 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:08.530 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:08.530 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:08.998 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:08.998 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:09.131 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:09.131 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:09.302 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:09.302 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:09.530 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:09.531 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:09.999 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:09.999 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:10.152 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:10.152 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:10.303 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:10.303 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:10.530 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:10.531 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:10.701 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:10,700 INFO  [org.keycloak.exportimport.util.ImportUtils] (main) Realm 'dexterity-apps-01' imported
2025-07-15 18:33:10.707 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:10,706 INFO  [org.keycloak.services] (main) KC-SERVICES0032: Import finished successfully
2025-07-15 18:33:10.852 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:10,851 INFO  [org.keycloak.services] (main) KC-SERVICES0077: Created temporary admin user with username admin
2025-07-15 18:33:11.000 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:11.001 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:11.060 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:11,059 INFO  [io.quarkus] (main) Keycloak 26.3.1 on JVM (powered by Quarkus 3.20.1) started in 15.376s. Listening on: http://0.0.0.0:8080. Management interface listening on http://0.0.0.0:9000.
2025-07-15 18:33:11.060 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:11,059 INFO  [io.quarkus] (main) Profile dev activated. 
2025-07-15 18:33:11.060 INFO  [docker-java-stream--1823905761] tc.keycloak/keycloak:26.3.1 - STDOUT: 2025-07-15 16:33:11,059 INFO  [io.quarkus] (main) Installed features: [agroal, cdi, hibernate-orm, jdbc-h2, keycloak, narayana-jta, opentelemetry, reactive-routes, rest, rest-jackson, smallrye-context-propagation, smallrye-health, vertx]
2025-07-15 18:33:11.152 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:11.153 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:11.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:11.350 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:11.577 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:11.577 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:11.841 INFO  [main] tc.keycloak/keycloak:26.3.1 - Container keycloak/keycloak:26.3.1 started in PT27.629423396S
2025-07-15 18:33:11.841 INFO  [main] tc.postgis/postgis:16-3.4 - Creating container for image: postgis/postgis:16-3.4
2025-07-15 18:33:11.903 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 is starting: 6308ce9cb2b17104800bb840d39c18e0b4363f933448c3cbf02067155ec1aecf
2025-07-15 18:33:12.001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:12.001 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:12.159 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:12.160 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:12.352 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:12.352 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:12.616 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:12.616 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:12.830 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:12.831 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:12.831 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:33:13.160 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:13.160 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:13.280 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:13.280 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:13.592 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:13.593 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:13.831 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:13.831 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:14.161 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:14.161 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:14.285 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:14.285 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:14.503 INFO  [main] tc.postgis/postgis:16-3.4 - Container postgis/postgis:16-3.4 started in PT2.661415598S
2025-07-15 18:33:14.503 INFO  [main] tc.postgis/postgis:16-3.4 - Container is started (JDBC URL: jdbc:postgresql://localhost:34742/DBBookAnythingPlatform?loggerLevel=OFF)
2025-07-15 18:33:14.513 INFO  [main] o.s.t.c.s.AnnotationConfigContextLoaderUtils - Could not detect default configuration classes for test class [de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.GeoLocationControllerIntegrationTest]: GeoLocationControllerIntegrationTest does not declare any static, non-private, non-final, nested classes annotated with @Configuration.
2025-07-15 18:33:14.601 INFO  [main] o.s.b.t.c.SpringBootTestContextBootstrapper - Found @SpringBootConfiguration de.org.dexterity.bookanything.BookAnythingBackendApplication for test class de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.GeoLocationControllerIntegrationTest
2025-07-15 18:33:14.621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:14.621 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:33:14.750 INFO  [main] d.o.d.b.d.i.a.i.w.c.GeoLocationControllerIntegrationTest - Starting GeoLocationControllerIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:33:14.751 INFO  [main] d.o.d.b.d.i.a.i.w.c.GeoLocationControllerIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:33:14.832 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:14.832 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:15.162 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:15.163 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:15.258 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:15.259 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:15.651 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:15.651 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:15.699 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:15.699 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:16.078 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:33:16.079 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:33:16.104 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.106 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.107 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.108 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.109 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.110 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.110 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.111 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:16.127 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 45 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:33:16.137 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:33:16.138 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:33:16.148 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:16.148 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:16.152 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:33:16.182 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 40 ms. Found 8 JPA repository interfaces.
2025-07-15 18:33:16.200 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:16.200 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:16.653 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:16.653 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:16.698 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:33:16.737 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:16.738 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:16.817 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@541f4873
2025-07-15 18:33:16.817 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:33:16.849 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:33:17.106 INFO  [main] liquibase.changelog - Creating database history table with name: public.databasechangelog
2025-07-15 18:33:17.133 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:33:17.141 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:17.141 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:17.150 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:17.150 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:17.153 INFO  [main] liquibase.snapshot - Creating snapshot
2025-07-15 18:33:17.194 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:33:17.198 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:33:17.204 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:33:17.205 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:33:17.205 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:33:17.205 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:33:17.205 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:33:17.205 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:33:17.205 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:33:17.206 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:33:17.323 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:33:17.336 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:33:17.339 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:33:17.371 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:33:17.371 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:33:17.390 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:33:17.394 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:33:17.627 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:33:17.655 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:17.655 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:17.739 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:17.739 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:17.808 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:33:17.809 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@599ed14d] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
Hibernate: 
    create table tb_address (
        id bigint generated by default as identity,
        ds_address_line2 varchar(255),
        ds_city_name varchar(255),
        ge_coordinates point,
        ds_country_name varchar(255),
        ds_district_name varchar(255),
        ds_door_number varchar(255),
        ds_floor_number varchar(255),
        ds_house_number varchar(255),
        ds_postal_code varchar(255),
        ds_province_name varchar(255),
        cd_status varchar(255) check (cd_status in ('ACTIVE','INACTIVE','INVALID')),
        ds_street_name varchar(255),
        district_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_geo_location (
        tp_geo_location varchar(31) not null,
        id bigint generated by default as identity,
        ge_geographic_boundary geometry,
        ds_name varchar(255),
        parent_id bigint,
        primary key (id)
    )
Hibernate: 
    create table tb_localizable_place (
        id uuid not null,
        ge_location geometry(Point,4326) not null,
        ds_name varchar(255) not null,
        primary key (id)
    )
Hibernate: 
    alter table if exists tb_localizable_place 
       drop constraint if exists UK9pal3kjaxjsq7ds5v9auatle7
2025-07-15 18:33:17.874 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - SQL Warning Code: 0, SQLState: 00000
2025-07-15 18:33:17.874 WARN  [task-1] o.h.e.jdbc.spi.SqlExceptionHelper - constraint "uk9pal3kjaxjsq7ds5v9auatle7" of relation "tb_localizable_place" does not exist, skipping
Hibernate: 
    alter table if exists tb_localizable_place 
       add constraint UK9pal3kjaxjsq7ds5v9auatle7 unique (ds_name)
Hibernate: 
    alter table if exists tb_address 
       add constraint FKbu1ghk29hk0af6sx3694jl6qe 
       foreign key (district_id) 
       references tb_geo_location
Hibernate: 
    alter table if exists tb_geo_location 
       add constraint fk01_region_continent 
       foreign key (parent_id) 
       references tb_geo_location
2025-07-15 18:33:17.885 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:33:18.155 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:18.156 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:18.180 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:18.181 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:18.657 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:18.657 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:18.737 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:18.737 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:19.158 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:19.158 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:19.181 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:19.181 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:19.561 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:19.561 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:19.738 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:19.739 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:19.952 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:33:20.158 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:20.159 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:20.181 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:20.181 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:20.301 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:33:20.301 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:33:20.303 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 2 ms
2025-07-15 18:33:20.358 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-31
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:20.359 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:20.386 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:20.386 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:20.386 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597200386
2025-07-15 18:33:20.395 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:33:20.402 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-32
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:20.402 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:20.427 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:20.428 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:20.428 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597200427
2025-07-15 18:33:20.433 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:33:20.439 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-33
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:20.440 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:20.450 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:20.450 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:20.451 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597200450
2025-07-15 18:33:20.458 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:33:20.461 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-34
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:20.462 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:20.468 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:20.468 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:20.468 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597200467
2025-07-15 18:33:20.477 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:33:20.480 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:33:20.511 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:20.511 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:20.580 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.580 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.580 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.581 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:20.582 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:20.582 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:20.584 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 3 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.585 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:20.735 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.738 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.739 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:20.739 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:20.744 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.757 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 7 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.773 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:33:20.808 INFO  [main] d.o.d.b.d.i.a.i.w.c.GeoLocationControllerIntegrationTest - Started GeoLocationControllerIntegrationTest in 6.182 seconds (process running for 531.222)
2025-07-15 18:33:20.957 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {geojson-upload-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.966 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-place-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.968 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-places-all-deleted-topic=LEADER_NOT_AVAILABLE}
2025-07-15 18:33:20.978 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] The metadata response from the cluster reported a recoverable issue with correlation id 9 : {localizable-place-created-topic=LEADER_NOT_AVAILABLE}
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, tp_geo_location) 
    values
        (?, ?, 'CONTINENT')
2025-07-15 18:33:21.166 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:21.167 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:21.183 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:21.184 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:21.326 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:21.327 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] (Re-)joining group
===> GeoLocation Created: GeoLocationResponse(type=CONTINENT, id=1, name=Continent-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=null)
2025-07-15 18:33:21.363 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:21.364 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:33:21.367 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-34-db4e6257-f221-4905-acf5-dc792d1c5fca
2025-07-15 18:33:21.368 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] (Re-)joining group
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:21.389 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-32-1da81c9c-091a-44ec-bb58-bdc5673b0384
2025-07-15 18:33:21.390 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:33:21.412 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:21.413 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:33:21.421 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-34-db4e6257-f221-4905-acf5-dc792d1c5fca', protocol='range'}
2025-07-15 18:33:21.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-34-db4e6257-f221-4905-acf5-dc792d1c5fca=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:33:21.429 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-33-18bf95fa-f888-4615-b042-8325f6b7ba0a
2025-07-15 18:33:21.429 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:33:21.430 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=1, memberId='consumer-geojson-processor-32-1da81c9c-091a-44ec-bb58-bdc5673b0384', protocol='range'}
2025-07-15 18:33:21.431 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:21.431 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:21.432 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Finished assignment for group at generation 1: {consumer-geojson-processor-32-1da81c9c-091a-44ec-bb58-bdc5673b0384=Assignment(partitions=[geojson-upload-topic-0])}
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:21.449 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-33-18bf95fa-f888-4615-b042-8325f6b7ba0a', protocol='range'}
2025-07-15 18:33:21.450 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Finished assignment for group at generation 1: {consumer-elasticsearch-indexer-33-18bf95fa-f888-4615-b042-8325f6b7ba0a=Assignment(partitions=[localizable-place-created-topic-0])}
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'REGION')
2025-07-15 18:33:21.465 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:21.466 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:33:21.481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-31-b91adb05-c727-4405-b0c6-7ef55ce74453
2025-07-15 18:33:21.482 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] (Re-)joining group
===> GeoLocation Created: GeoLocationResponse(type=REGION, id=2, name=Region-1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=1)
2025-07-15 18:33:21.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-31-b91adb05-c727-4405-b0c6-7ef55ce74453', protocol='range'}
2025-07-15 18:33:21.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 1: {consumer-elasticsearch-deleter-all-31-b91adb05-c727-4405-b0c6-7ef55ce74453=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
2025-07-15 18:33:21.565 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=1, memberId='consumer-geojson-processor-32-1da81c9c-091a-44ec-bb58-bdc5673b0384', protocol='range'}
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-34-db4e6257-f221-4905-acf5-dc792d1c5fca', protocol='range'}
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-deleter-all-31-b91adb05-c727-4405-b0c6-7ef55ce74453', protocol='range'}
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=1, memberId='consumer-elasticsearch-indexer-33-18bf95fa-f888-4615-b042-8325f6b7ba0a', protocol='range'}
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:33:21.566 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:33:21.567 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
2025-07-15 18:33:21.593 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:33:21.593 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:33:21.594 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:33:21.599 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Found no committed offset for partition localizable-place-created-topic-0
2025-07-15 18:33:21.600 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Found no committed offset for partition geojson-upload-topic-0
2025-07-15 18:33:21.600 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
2025-07-15 18:33:21.605 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Found no committed offset for partition localizable-places-all-deleted-topic-0
2025-07-15 18:33:21.605 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Found no committed offset for partition localizable-place-deleted-topic-0
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=3, name=Country-1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=2)
2025-07-15 18:33:21.635 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Resetting offset for partition localizable-place-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:33:21.635 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Resetting offset for partition localizable-place-created-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}.
2025-07-15 18:33:21.636 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Resetting offset for partition geojson-upload-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
2025-07-15 18:33:21.639 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Resetting offset for partition localizable-places-all-deleted-topic-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}.
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:21.708 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:33:21.711 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:33:21.712 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:33:21.713 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
2025-07-15 18:33:21.741 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:21.741 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:21.750 WARN  [Hikari:connection-adder] com.zaxxer.hikari.pool.PoolBase - Hikari - Pool is empty, failed to create/setup connection (4a5b64e0-0172-4e7a-b55a-21c018462c5a)
org.postgresql.util.PSQLException: Connection to localhost:34717 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:373)
	at org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:57)
	at org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:277)
	at org.postgresql.Driver.makeConnection(Driver.java:448)
	at org.postgresql.Driver.connect(Driver.java:298)
	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:139)
	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:368)
	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:205)
	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:483)
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:747)
	at com.zaxxer.hikari.pool.HikariPool$PoolEntryCreator.call(HikariPool.java:726)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542)
	at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:592)
	at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327)
	at java.base/java.net.Socket.connect(Socket.java:751)
	at org.postgresql.core.PGStream.createSocket(PGStream.java:261)
	at org.postgresql.core.PGStream.<init>(PGStream.java:122)
	at org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:146)
	at org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:289)
	... 14 common frames omitted
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=4, name=Province-1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=3)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=5, name=City-1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=4)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=6, name=District-1.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=5)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=7, name=District-1.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=5)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=8, name=City-1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=4)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
2025-07-15 18:33:22.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:22.167 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=9, name=District-1.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=8)
2025-07-15 18:33:22.184 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:22.184 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=10, name=District-1.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=8)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=11, name=Province-1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=3)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=12, name=City-1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=11)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=13, name=District-1.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=12)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=14, name=District-1.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=12)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
2025-07-15 18:33:22.461 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:22.461 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=15, name=City-1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=11)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=16, name=District-1.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=15)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=17, name=District-1.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=15)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=18, name=Province-1.1.1.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=3)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=19, name=City-1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=18)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=20, name=District-1.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=19)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=21, name=District-1.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=19)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=22, name=City-1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=18)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=23, name=District-1.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=22)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
2025-07-15 18:33:22.742 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:22.742 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=24, name=District-1.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=22)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=25, name=Province-1.1.1.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=3)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=26, name=City-1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=25)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=27, name=District-1.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=26)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=28, name=District-1.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=26)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=29, name=City-1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=25)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=30, name=District-1.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=29)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=31, name=District-1.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=29)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=32, name=Country-1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=2)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=33, name=Province-1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=32)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=34, name=City-1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=33)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=35, name=District-1.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=34)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=36, name=District-1.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=34)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=37, name=City-1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=33)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=38, name=District-1.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=37)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=39, name=District-1.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=37)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
2025-07-15 18:33:23.160 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:23.160 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=40, name=Province-1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=32)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:23.185 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:23.185 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=41, name=City-1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=40)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=42, name=District-1.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=41)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=43, name=District-1.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=41)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=44, name=City-1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=40)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=45, name=District-1.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=44)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=46, name=District-1.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=44)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=47, name=Province-1.1.2.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=32)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=48, name=City-1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=47)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=49, name=District-1.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=48)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=50, name=District-1.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=48)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:23.462 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:23.462 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=51, name=City-1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=47)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=52, name=District-1.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=51)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=53, name=District-1.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=51)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=54, name=Province-1.1.2.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=32)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=55, name=City-1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=54)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=56, name=District-1.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=55)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=57, name=District-1.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=55)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=58, name=City-1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=54)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=59, name=District-1.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=58)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=60, name=District-1.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=58)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'REGION')
===> GeoLocation Created: GeoLocationResponse(type=REGION, id=61, name=Region-1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=1)
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=62, name=Country-1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=61)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=63, name=Province-1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=62)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
2025-07-15 18:33:23.743 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
2025-07-15 18:33:23.743 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=64, name=City-1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=63)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=65, name=District-1.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=64)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=66, name=District-1.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=64)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=67, name=City-1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=63)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=68, name=District-1.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=67)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=69, name=District-1.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=67)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=70, name=Province-1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=62)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=71, name=City-1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=70)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=72, name=District-1.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=71)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=73, name=District-1.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=71)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=74, name=City-1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=70)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=75, name=District-1.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=74)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=76, name=District-1.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=74)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=77, name=Province-1.2.1.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=62)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=78, name=City-1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=77)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=79, name=District-1.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=78)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=80, name=District-1.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=78)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:24.063 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:24.063 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=81, name=City-1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=77)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=82, name=District-1.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=81)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=83, name=District-1.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=81)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=84, name=Province-1.2.1.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=62)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=85, name=City-1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=84)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=86, name=District-1.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=85)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
2025-07-15 18:33:24.186 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:24.186 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=87, name=District-1.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=85)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=88, name=City-1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=84)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=89, name=District-1.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=88)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=90, name=District-1.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=88)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=91, name=Country-1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=61)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=92, name=Province-1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=91)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=93, name=City-1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=92)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=94, name=District-1.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=93)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=95, name=District-1.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=93)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=96, name=City-1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=92)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=97, name=District-1.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=96)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=98, name=District-1.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=96)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=99, name=Province-1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=91)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=100, name=City-1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=99)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:24.462 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:24.463 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=101, name=District-1.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=100)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=102, name=District-1.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=100)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=103, name=City-1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=99)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=104, name=District-1.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=103)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=105, name=District-1.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=103)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=106, name=Province-1.2.2.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=91)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=107, name=City-1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=106)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=108, name=District-1.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=107)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=109, name=District-1.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=107)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=110, name=City-1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=106)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=111, name=District-1.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=110)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=112, name=District-1.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=110)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=113, name=Province-1.2.2.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=91)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=114, name=City-1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=113)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=115, name=District-1.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=114)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:24.744 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:24.744 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=116, name=District-1.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=114)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=117, name=City-1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=113)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=118, name=District-1.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=117)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=119, name=District-1.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=117)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, tp_geo_location) 
    values
        (?, ?, 'CONTINENT')
===> GeoLocation Created: GeoLocationResponse(type=CONTINENT, id=120, name=Continent-2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=null)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'REGION')
===> GeoLocation Created: GeoLocationResponse(type=REGION, id=121, name=Region-2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=120)
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=122, name=Country-2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=121)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=123, name=Province-2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=122)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=124, name=City-2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=123)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=125, name=District-2.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=124)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=126, name=District-2.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=124)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=127, name=City-2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=123)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=128, name=District-2.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=127)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=129, name=District-2.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=127)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=130, name=Province-2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=122)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=131, name=City-2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=130)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=132, name=District-2.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=131)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=133, name=District-2.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=131)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=134, name=City-2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=130)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
2025-07-15 18:33:25.063 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:25.064 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=135, name=District-2.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=134)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=136, name=District-2.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=134)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=137, name=Province-2.1.1.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=122)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=138, name=City-2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=137)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=139, name=District-2.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=138)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=140, name=District-2.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=138)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=141, name=City-2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=137)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=142, name=District-2.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=141)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:25.194 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:25.194 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=143, name=District-2.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=141)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=144, name=Province-2.1.1.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=122)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=145, name=City-2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=144)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=146, name=District-2.1.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=145)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=147, name=District-2.1.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=145)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=148, name=City-2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=144)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=149, name=District-2.1.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=148)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=150, name=District-2.1.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=148)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=151, name=Country-2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=121)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=152, name=Province-2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=151)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=153, name=City-2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=152)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=154, name=District-2.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=153)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=155, name=District-2.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=153)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=156, name=City-2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=152)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=157, name=District-2.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=156)
2025-07-15 18:33:25.463 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:25.463 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=158, name=District-2.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=156)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=159, name=Province-2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=151)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=160, name=City-2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=159)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=161, name=District-2.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=160)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=162, name=District-2.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=160)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=163, name=City-2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=159)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=164, name=District-2.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=163)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=165, name=District-2.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=163)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=166, name=Province-2.1.2.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=151)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=167, name=City-2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=166)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=168, name=District-2.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=167)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=169, name=District-2.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=167)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=170, name=City-2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=166)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=171, name=District-2.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=170)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=172, name=District-2.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=170)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=173, name=Province-2.1.2.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=151)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:25.744 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:25.745 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=174, name=City-2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=173)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=175, name=District-2.1.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=174)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=176, name=District-2.1.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=174)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=177, name=City-2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=173)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=178, name=District-2.1.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=177)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=179, name=District-2.1.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=177)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'REGION')
===> GeoLocation Created: GeoLocationResponse(type=REGION, id=180, name=Region-2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=120)
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=181, name=Country-2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=180)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=182, name=Province-2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=181)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=183, name=City-2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=182)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=184, name=District-2.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=183)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=185, name=District-2.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=183)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=186, name=City-2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=182)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=187, name=District-2.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=186)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=188, name=District-2.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=186)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=189, name=Province-2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=181)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=190, name=City-2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=189)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=191, name=District-2.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=190)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
2025-07-15 18:33:26.089 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:26.090 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=192, name=District-2.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=190)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=193, name=City-2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=189)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=194, name=District-2.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=193)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=195, name=District-2.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=193)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=196, name=Province-2.2.1.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=181)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=197, name=City-2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=196)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
2025-07-15 18:33:26.196 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:26.196 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=198, name=District-2.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=197)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=199, name=District-2.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=197)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=200, name=City-2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=196)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=201, name=District-2.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=200)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=202, name=District-2.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=200)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=203, name=Province-2.2.1.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=181)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=204, name=City-2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=203)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=205, name=District-2.2.1.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=204)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=206, name=District-2.2.1.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=204)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=207, name=City-2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=203)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=208, name=District-2.2.1.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=207)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=209, name=District-2.2.1.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=207)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=210, name=Country-2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=180)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=211, name=Province-2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=210)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=212, name=City-2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=211)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=213, name=District-2.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=212)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:26.464 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
2025-07-15 18:33:26.464 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=214, name=District-2.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=212)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=215, name=City-2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=211)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=216, name=District-2.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=215)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=217, name=District-2.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=215)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=218, name=Province-2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=210)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=219, name=City-2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=218)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=220, name=District-2.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=219)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=221, name=District-2.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=219)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=222, name=City-2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=218)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=223, name=District-2.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=222)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=224, name=District-2.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=222)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=225, name=Province-2.2.2.3, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=210)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=226, name=City-2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=225)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=227, name=District-2.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=226)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=228, name=District-2.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=226)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=229, name=City-2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=225)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=230, name=District-2.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=229)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
2025-07-15 18:33:26.745 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:26.745 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=231, name=District-2.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=229)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=232, name=Province-2.2.2.4, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=210)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=233, name=City-2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=232)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=234, name=District-2.2.2.1.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=233)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=235, name=District-2.2.2.1.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=233)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=236, name=City-2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=232)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=237, name=District-2.2.2.2.1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=236)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=238, name=District-2.2.2.2.2, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=236)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT'
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY'
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY'
2025-07-15 18:33:27.011 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:27.011 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY'
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE'
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY'
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY'
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY'
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION'
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT'
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT'
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY'
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY'
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT'
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-34-db4e6257-f221-4905-acf5-dc792d1c5fca sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Member consumer-geojson-processor-32-1da81c9c-091a-44ec-bb58-bdc5673b0384 sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-33-18bf95fa-f888-4615-b042-8325f6b7ba0a sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-31-b91adb05-c727-4405-b0c6-7ef55ce74453 sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:27.167 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-31, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-32, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-33, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.168 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-34, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:27.197 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:27.197 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:27.378 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:27.378 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:27.378 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:27.378 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:27.379 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:27.379 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:27.379 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:27.379 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:27.380 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:27.387 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:27.387 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:27.387 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:27.388 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:27.388 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:27.388 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:27.388 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:27.399 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-33 unregistered
2025-07-15 18:33:27.400 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:33:27.401 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-32 unregistered
2025-07-15 18:33:27.402 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:33:27.403 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-34 unregistered
2025-07-15 18:33:27.403 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:33:27.404 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-31 unregistered
2025-07-15 18:33:27.404 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:33:27.412 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:33:27.413 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:33:27.414 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.

  .   ____          _            __ _ _
 /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
  '  |____| .__|_| |_|_| |_\__, | / / / /
 =========|_|==============|___/=/_/_/_/

 :: Spring Boot ::                (v3.5.3)

2025-07-15 18:33:27.457 INFO  [main] d.o.d.b.d.i.a.i.w.c.GeoLocationControllerIntegrationTest - Starting GeoLocationControllerIntegrationTest using Java 21.0.6 with PID 3038481 (started by andre.nascimento in /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01)
2025-07-15 18:33:27.458 INFO  [main] d.o.d.b.d.i.a.i.w.c.GeoLocationControllerIntegrationTest - No active profile set, falling back to 1 default profile: "default"
2025-07-15 18:33:27.504 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:27.504 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:27.746 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:27.747 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:27.788 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:33:27.788 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data Elasticsearch repositories in DEFAULT mode.
2025-07-15 18:33:27.799 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.AddressJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.799 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CityJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.800 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ContinentJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.800 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.CountryJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.800 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.DistrictJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.800 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.LocalizablePlaceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.800 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.ProvinceJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.800 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data Elasticsearch - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.repositories.RegionJpaRepository; If you want this repository to be a Elasticsearch repository, consider annotating your entities with one of these annotations: org.springframework.data.elasticsearch.annotations.Document (preferred), or consider extending one of the following types with your repository: org.springframework.data.elasticsearch.repository.ElasticsearchRepository
2025-07-15 18:33:27.812 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 21 ms. Found 1 Elasticsearch repository interface.
2025-07-15 18:33:27.820 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Multiple Spring Data modules found, entering strict repository configuration mode
2025-07-15 18:33:27.820 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Bootstrapping Spring Data JPA repositories in DEFERRED mode.
2025-07-15 18:33:27.831 INFO  [main] o.s.d.r.c.RepositoryConfigurationExtensionSupport - Spring Data JPA - Could not safely identify store assignment for repository candidate interface de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.elasticsearch.repositories.LocalizablePlaceElasticRepository; If you want this repository to be a JPA repository, consider annotating your entities with one of these annotations: jakarta.persistence.Entity, jakarta.persistence.MappedSuperclass (preferred), or consider extending one of the following types with your repository: org.springframework.data.jpa.repository.JpaRepository
2025-07-15 18:33:27.850 INFO  [main] o.s.d.r.c.RepositoryConfigurationDelegate - Finished Spring Data repository scanning in 28 ms. Found 8 JPA repository interfaces.
2025-07-15 18:33:28.048 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:28.048 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:28.115 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Starting...
2025-07-15 18:33:28.136 INFO  [main] com.zaxxer.hikari.pool.HikariPool - Hikari - Added connection org.postgresql.jdbc.PgConnection@1dfd8f40
2025-07-15 18:33:28.137 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Start completed.
2025-07-15 18:33:28.159 INFO  [main] liquibase.database - Set default schema name to public
2025-07-15 18:33:28.200 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:28.200 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:28.312 INFO  [main] liquibase.changelog - Reading from public.databasechangelog
2025-07-15 18:33:28.341 INFO  [main] liquibase.ui - Database is up to date, no changesets to execute
2025-07-15 18:33:28.343 INFO  [main] liquibase.util - UPDATE SUMMARY
2025-07-15 18:33:28.343 INFO  [main] liquibase.util - Run:                          0
2025-07-15 18:33:28.344 INFO  [main] liquibase.util - Previously run:               0
2025-07-15 18:33:28.344 INFO  [main] liquibase.util - Filtered out:                 0
2025-07-15 18:33:28.344 INFO  [main] liquibase.util - -------------------------------
2025-07-15 18:33:28.344 INFO  [main] liquibase.util - Total change sets:            0
2025-07-15 18:33:28.344 INFO  [main] liquibase.util - Update summary generated
2025-07-15 18:33:28.344 INFO  [main] liquibase.command - Command execution complete
2025-07-15 18:33:28.427 INFO  [task-1] o.h.jpa.internal.util.LogHelper - HHH000204: Processing PersistenceUnitInfo [name: default]
2025-07-15 18:33:28.435 INFO  [task-1] o.h.s.integration.SpatialService - HHH80000001: hibernate-spatial integration enabled : true
2025-07-15 18:33:28.438 INFO  [task-1] o.h.c.i.RegionFactoryInitiator - HHH000026: Second-level cache disabled
2025-07-15 18:33:28.458 INFO  [task-1] o.hibernate.orm.connections.pooling - HHH10001005: Database info:
	Database JDBC URL [Connecting through datasource 'HikariDataSource (Hikari)']
	Database driver: undefined/unknown
	Database version: 16.4
	Autocommit mode: undefined/unknown
	Isolation level: undefined/unknown
	Minimum pool size: undefined/unknown
	Maximum pool size: undefined/unknown
2025-07-15 18:33:28.458 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:33:28.468 INFO  [task-1] o.s.o.j.p.SpringPersistenceUnitInfo - No LoadTimeWeaver setup: ignoring JPA class transformer
2025-07-15 18:33:28.471 INFO  [task-1] org.hibernate.spatial - HHH80000003: hibernate-spatial adding type contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:33:28.505 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:28.505 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:28.605 INFO  [task-1] org.hibernate.spatial - HHH80000004: hibernate-spatial adding function contributions from : org.hibernate.spatial.dialect.postgis.PostgisDialectContributor
2025-07-15 18:33:28.720 INFO  [task-1] o.h.e.t.j.p.i.JtaPlatformInitiator - HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
2025-07-15 18:33:28.721 INFO  [task-1] o.hibernate.orm.connections.access - HHH10001501: Connection obtained from JdbcConnectionAccess [org.hibernate.engine.jdbc.env.internal.JdbcEnvironmentInitiator$ConnectionProviderJdbcConnectionAccess@21c8671e] for (non-JTA) DDL execution was not in auto-commit mode; the Connection 'local transaction' will be committed and the Connection will be set into auto-commit mode.
2025-07-15 18:33:28.748 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:28.749 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:28.996 INFO  [task-1] o.s.o.j.LocalContainerEntityManagerFactoryBean - Initialized JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:33:29.049 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:29.049 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:29.057 INFO  [main] o.s.b.a.e.web.EndpointLinksResolver - Exposing 6 endpoints beneath base path '/management'
2025-07-15 18:33:29.162 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:29.162 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:29.329 INFO  [main] o.s.b.t.m.w.SpringBootMockServletContext - Initializing Spring TestDispatcherServlet ''
2025-07-15 18:33:29.329 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Initializing Servlet ''
2025-07-15 18:33:29.331 INFO  [main] o.s.t.w.s.TestDispatcherServlet - Completed initialization in 2 ms
2025-07-15 18:33:29.367 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-all-35
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter-all
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:29.368 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:29.375 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:29.375 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:29.375 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597209375
2025-07-15 18:33:29.377 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Subscribed to topic(s): localizable-places-all-deleted-topic
2025-07-15 18:33:29.379 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-geojson-processor-36
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = geojson-processor
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:29.380 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:29.386 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:29.386 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:29.387 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597209386
2025-07-15 18:33:29.390 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Subscribed to topic(s): geojson-upload-topic
2025-07-15 18:33:29.392 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:29.393 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-indexer-37
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-indexer
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:29.393 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:29.394 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:29.394 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:33:29.400 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:29.402 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:29.402 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:29.402 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597209401
2025-07-15 18:33:29.402 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:29.404 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:33:29.404 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-all-35-7f7e6804-700f-4071-a045-1ef4927fac5c
2025-07-15 18:33:29.405 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] (Re-)joining group
2025-07-15 18:33:29.409 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Subscribed to topic(s): localizable-place-created-topic
2025-07-15 18:33:29.414 INFO  [main] o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [PLAINTEXT://localhost:34738]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-elasticsearch-deleter-38
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = elasticsearch-deleter
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 52428800
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.header.urlencode = false
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.ErrorHandlingDeserializer

2025-07-15 18:33:29.414 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Successfully joined group with generation Generation{generationId=3, memberId='consumer-elasticsearch-deleter-all-35-7f7e6804-700f-4071-a045-1ef4927fac5c', protocol='range'}
2025-07-15 18:33:29.414 INFO  [main] o.a.k.c.t.i.KafkaMetricsCollector - initializing Kafka metrics collector
2025-07-15 18:33:29.414 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Finished assignment for group at generation 3: {consumer-elasticsearch-deleter-all-35-7f7e6804-700f-4071-a045-1ef4927fac5c=Assignment(partitions=[localizable-places-all-deleted-topic-0])}
2025-07-15 18:33:29.415 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Request joining group due to: need to re-join with the given member-id: consumer-geojson-processor-36-9ae66e23-eefc-4d71-bde5-591599e6dcd2
2025-07-15 18:33:29.416 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] (Re-)joining group
2025-07-15 18:33:29.419 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka version: 3.9.1
2025-07-15 18:33:29.419 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka commitId: f745dfdcee2b9851
2025-07-15 18:33:29.419 INFO  [main] o.a.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1752597209419
2025-07-15 18:33:29.421 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Successfully joined group with generation Generation{generationId=3, memberId='consumer-geojson-processor-36-9ae66e23-eefc-4d71-bde5-591599e6dcd2', protocol='range'}
2025-07-15 18:33:29.422 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Finished assignment for group at generation 3: {consumer-geojson-processor-36-9ae66e23-eefc-4d71-bde5-591599e6dcd2=Assignment(partitions=[geojson-upload-topic-0])}
2025-07-15 18:33:29.423 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:29.424 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:29.426 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:33:29.426 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Successfully synced group in generation Generation{generationId=3, memberId='consumer-elasticsearch-deleter-all-35-7f7e6804-700f-4071-a045-1ef4927fac5c', protocol='range'}
2025-07-15 18:33:29.427 INFO  [main] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Subscribed to topic(s): localizable-place-deleted-topic
2025-07-15 18:33:29.427 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Notifying assignor about the new Assignment(partitions=[localizable-places-all-deleted-topic-0])
2025-07-15 18:33:29.427 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Adding newly assigned partitions: localizable-places-all-deleted-topic-0
2025-07-15 18:33:29.431 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Triggering deferred initialization of Spring Data repositories…
2025-07-15 18:33:29.432 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Successfully synced group in generation Generation{generationId=3, memberId='consumer-geojson-processor-36-9ae66e23-eefc-4d71-bde5-591599e6dcd2', protocol='range'}
2025-07-15 18:33:29.434 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Notifying assignor about the new Assignment(partitions=[geojson-upload-topic-0])
2025-07-15 18:33:29.434 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Adding newly assigned partitions: geojson-upload-topic-0
2025-07-15 18:33:29.436 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition localizable-places-all-deleted-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:33:29.437 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions assigned: [localizable-places-all-deleted-topic-0]
2025-07-15 18:33:29.438 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-indexer-37-0ddbc264-db50-43ba-88df-da4dad5596ea
2025-07-15 18:33:29.439 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] (Re-)joining group
2025-07-15 18:33:29.446 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition geojson-upload-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:33:29.447 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions assigned: [geojson-upload-topic-0]
2025-07-15 18:33:29.447 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Cluster ID: XuKuw6xwTzuY_pK4ErGPWg
2025-07-15 18:33:29.448 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Successfully joined group with generation Generation{generationId=3, memberId='consumer-elasticsearch-indexer-37-0ddbc264-db50-43ba-88df-da4dad5596ea', protocol='range'}
2025-07-15 18:33:29.448 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Finished assignment for group at generation 3: {consumer-elasticsearch-indexer-37-0ddbc264-db50-43ba-88df-da4dad5596ea=Assignment(partitions=[localizable-place-created-topic-0])}
2025-07-15 18:33:29.448 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Discovered group coordinator localhost:34738 (id: 2147483646 rack: null)
2025-07-15 18:33:29.449 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:33:29.455 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Successfully synced group in generation Generation{generationId=3, memberId='consumer-elasticsearch-indexer-37-0ddbc264-db50-43ba-88df-da4dad5596ea', protocol='range'}
2025-07-15 18:33:29.456 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Notifying assignor about the new Assignment(partitions=[localizable-place-created-topic-0])
2025-07-15 18:33:29.457 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Adding newly assigned partitions: localizable-place-created-topic-0
2025-07-15 18:33:29.460 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Request joining group due to: need to re-join with the given member-id: consumer-elasticsearch-deleter-38-75a72e54-6b08-4254-b381-a1c24c5221f8
2025-07-15 18:33:29.461 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] (Re-)joining group
2025-07-15 18:33:29.465 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition localizable-place-created-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:33:29.466 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions assigned: [localizable-place-created-topic-0]
2025-07-15 18:33:29.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Successfully joined group with generation Generation{generationId=3, memberId='consumer-elasticsearch-deleter-38-75a72e54-6b08-4254-b381-a1c24c5221f8', protocol='range'}
2025-07-15 18:33:29.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Finished assignment for group at generation 3: {consumer-elasticsearch-deleter-38-75a72e54-6b08-4254-b381-a1c24c5221f8=Assignment(partitions=[localizable-place-deleted-topic-0])}
2025-07-15 18:33:29.483 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Successfully synced group in generation Generation{generationId=3, memberId='consumer-elasticsearch-deleter-38-75a72e54-6b08-4254-b381-a1c24c5221f8', protocol='range'}
2025-07-15 18:33:29.484 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Notifying assignor about the new Assignment(partitions=[localizable-place-deleted-topic-0])
2025-07-15 18:33:29.484 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Adding newly assigned partitions: localizable-place-deleted-topic-0
2025-07-15 18:33:29.492 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.internals.ConsumerUtils - Setting offset for partition localizable-place-deleted-topic-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:34738 (id: 1 rack: null)], epoch=0}}
2025-07-15 18:33:29.492 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions assigned: [localizable-place-deleted-topic-0]
2025-07-15 18:33:29.506 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:29.507 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:29.639 INFO  [main] o.s.d.r.c.DeferredRepositoryInitializationListener - Spring Data repositories initialized
2025-07-15 18:33:29.676 INFO  [main] d.o.d.b.d.i.a.i.w.c.GeoLocationControllerIntegrationTest - Started GeoLocationControllerIntegrationTest in 2.254 seconds (process running for 540.09)
2025-07-15 18:33:29.750 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:29.750 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, tp_geo_location) 
    values
        (?, ?, 'CONTINENT')
===> GeoLocation Created: GeoLocationResponse(type=CONTINENT, id=239, name=Continent-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=null)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    update
        tb_geo_location 
    set
        ge_geographic_boundary=?,
        ds_name=? 
    where
        id=?
===> GeoLocation Updated: GeoLocationResponse(type=CONTINENT, id=239, name=Updated - Continent-1, boundaryRepresentation=POLYGON ((15 15, 15 25, 25 25, 25 15, 15 15)), parentId=null)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'REGION')
===> GeoLocation Created: GeoLocationResponse(type=REGION, id=240, name=Region-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=239)
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    update
        tb_geo_location 
    set
        ge_geographic_boundary=?,
        ds_name=?,
        parent_id=? 
    where
        id=?
===> GeoLocation Updated: GeoLocationResponse(type=REGION, id=240, name=Updated - Region-1, boundaryRepresentation=POLYGON ((15 15, 15 25, 25 25, 25 15, 15 15)), parentId=239)
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'COUNTRY')
===> GeoLocation Created: GeoLocationResponse(type=COUNTRY, id=241, name=Country-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=240)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    update
        tb_geo_location 
    set
        ge_geographic_boundary=?,
        ds_name=?,
        parent_id=? 
    where
        id=?
===> GeoLocation Updated: GeoLocationResponse(type=COUNTRY, id=241, name=Updated - Country-1, boundaryRepresentation=POLYGON ((15 15, 15 25, 25 25, 25 15, 15 15)), parentId=240)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY'
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'PROVINCE')
===> GeoLocation Created: GeoLocationResponse(type=PROVINCE, id=242, name=Province-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=241)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
2025-07-15 18:33:30.050 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:30.050 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    update
        tb_geo_location 
    set
        ge_geographic_boundary=?,
        ds_name=?,
        parent_id=? 
    where
        id=?
===> GeoLocation Updated: GeoLocationResponse(type=PROVINCE, id=242, name=Updated - Province-1, boundaryRepresentation=POLYGON ((15 15, 15 25, 25 25, 25 15, 15 15)), parentId=241)
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'CITY')
===> GeoLocation Created: GeoLocationResponse(type=CITY, id=243, name=City-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=242)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    update
        tb_geo_location 
    set
        ge_geographic_boundary=?,
        ds_name=?,
        parent_id=? 
    where
        id=?
===> GeoLocation Updated: GeoLocationResponse(type=CITY, id=243, name=Updated - City-1, boundaryRepresentation=POLYGON ((15 15, 15 25, 25 25, 25 15, 15 15)), parentId=242)
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY'
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
2025-07-15 18:33:30.158 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:30.159 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
Hibernate: 
    insert 
    into
        tb_geo_location
        (ge_geographic_boundary, ds_name, parent_id, tp_geo_location) 
    values
        (?, ?, ?, 'DISTRICT')
===> GeoLocation Created: GeoLocationResponse(type=DISTRICT, id=244, name=District-1, boundaryRepresentation=POLYGON ((10 10, 10 20, 20 20, 20 10, 10 10)), parentId=243)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    update
        tb_geo_location 
    set
        ge_geographic_boundary=?,
        ds_name=?,
        parent_id=? 
    where
        id=?
===> GeoLocation Updated: GeoLocationResponse(type=DISTRICT, id=244, name=Updated - District-1, boundaryRepresentation=POLYGON ((15 15, 15 25, 25 25, 25 15, 15 15)), parentId=243)
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT' 
        and de1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY' 
        and ce1_0.id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE' 
        and pe1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY' 
        and ce1_0.id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION' 
        and re1_0.id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    delete 
    from
        tb_geo_location 
    where
        id=?
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT' 
        and ce1_0.id=?
Hibernate: 
    select
        de1_0.id,
        de1_0.ge_geographic_boundary,
        de1_0.ds_name,
        de1_0.parent_id,
        de1_0.tp_geo_location 
    from
        tb_geo_location de1_0 
    where
        de1_0.tp_geo_location='DISTRICT'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CITY'
Hibernate: 
    select
        pe1_0.id,
        pe1_0.ge_geographic_boundary,
        pe1_0.ds_name,
        pe1_0.parent_id,
        pe1_0.tp_geo_location 
    from
        tb_geo_location pe1_0 
    where
        pe1_0.tp_geo_location='PROVINCE'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='COUNTRY'
Hibernate: 
    select
        re1_0.id,
        re1_0.ge_geographic_boundary,
        re1_0.ds_name,
        re1_0.parent_id,
        re1_0.tp_geo_location 
    from
        tb_geo_location re1_0 
    where
        re1_0.tp_geo_location='REGION'
Hibernate: 
    select
        ce1_0.id,
        ce1_0.ge_geographic_boundary,
        ce1_0.ds_name,
        ce1_0.parent_id,
        ce1_0.tp_geo_location 
    from
        tb_geo_location ce1_0 
    where
        ce1_0.tp_geo_location='CONTINENT'
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Revoke previously assigned partitions localizable-place-deleted-topic-0
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Revoke previously assigned partitions geojson-upload-topic-0
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Revoke previously assigned partitions localizable-place-created-topic-0
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerRebalanceListenerInvoker - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Revoke previously assigned partitions localizable-places-all-deleted-topic-0
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: partitions revoked: [localizable-place-deleted-topic-0]
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: partitions revoked: [geojson-upload-topic-0]
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: partitions revoked: [localizable-places-all-deleted-topic-0]
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Member consumer-elasticsearch-deleter-38-75a72e54-6b08-4254-b381-a1c24c5221f8 sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: partitions revoked: [localizable-place-created-topic-0]
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Member consumer-geojson-processor-36-9ae66e23-eefc-4d71-bde5-591599e6dcd2 sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Member consumer-elasticsearch-deleter-all-35-7f7e6804-700f-4071-a045-1ef4927fac5c sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Member consumer-elasticsearch-indexer-37-0ddbc264-db50-43ba-88df-da4dad5596ea sending LeaveGroup request to coordinator localhost:34738 (id: 2147483646 rack: null) due to the consumer unsubscribed from all topics
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.349 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ClassicKafkaConsumer - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Unsubscribed all topics or patterns and assigned partitions
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-geojson-processor-36, groupId=geojson-processor] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Resetting generation and member id due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-indexer-37, groupId=elasticsearch-indexer] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-all-35, groupId=elasticsearch-deleter-all] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.350 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=consumer-elasticsearch-deleter-38, groupId=elasticsearch-deleter] Request joining group due to: consumer pro-actively leaving the group
2025-07-15 18:33:30.466 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:30.466 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:30.466 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:30.466 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:30.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-all-35 unregistered
2025-07-15 18:33:30.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter-all: Consumer stopped
2025-07-15 18:33:30.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:30.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:30.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:30.469 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:30.472 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-geojson-processor-36 unregistered
2025-07-15 18:33:30.473 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.s.k.l.KafkaMessageListenerContainer - geojson-processor: Consumer stopped
2025-07-15 18:33:30.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:30.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:30.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:30.490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:30.497 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-indexer-37 unregistered
2025-07-15 18:33:30.498 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-indexer: Consumer stopped
2025-07-15 18:33:30.507 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:30.507 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:30.516 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics scheduler closed
2025-07-15 18:33:30.517 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2025-07-15 18:33:30.517 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter
2025-07-15 18:33:30.517 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.metrics.Metrics - Metrics reporters closed
2025-07-15 18:33:30.522 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.a.kafka.common.utils.AppInfoParser - App info kafka.consumer for consumer-elasticsearch-deleter-38 unregistered
2025-07-15 18:33:30.522 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer - elasticsearch-deleter: Consumer stopped
2025-07-15 18:33:30.540 INFO  [main] o.s.o.j.LocalContainerEntityManagerFactoryBean - Closing JPA EntityManagerFactory for persistence unit 'default'
2025-07-15 18:33:30.543 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown initiated...
2025-07-15 18:33:30.545 INFO  [main] com.zaxxer.hikari.HikariDataSource - Hikari - Shutdown completed.
2025-07-15 18:33:30.751 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:30.751 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:30.953 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:30.953 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:31.202 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:31.202 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:31.471 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:31.471 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:31.752 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:31.752 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:31.954 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:31.954 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 76.80 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.GeoLocationControllerIntegrationTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.GeoLocationControllerTest
2025-07-15 18:33:32.243 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:32.244 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:32.529 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:32.529 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.474 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.controllers.GeoLocationControllerTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.mappers.AddressRestMapperTest
[INFO] Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.006 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.mappers.AddressRestMapperTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.mappers.GeoLocationRestMapperTest
[INFO] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.input.web.mappers.GeoLocationRestMapperTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.AddressPersistenceJpaAdapterTest
2025-07-15 18:33:32.762 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:32.763 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:32.959 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:32.960 WARN  [kafka-coordinator-heartbeat-thread | geojson-processor] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:32.960 INFO  [kafka-coordinator-heartbeat-thread | geojson-processor] o.a.k.clients.FetchSessionHandler - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2025-07-15 18:33:33.280 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:33.280 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:33.615 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:33.615 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:33.797 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:33.797 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.230 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.AddressPersistenceJpaAdapterTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.CityPersistenceJpaAdapterTest
2025-07-15 18:33:34.001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:34.001 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:34.339 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:34.340 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:34.626 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:34.626 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.849 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.CityPersistenceJpaAdapterTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.ContinentPersistenceJpaAdapterTest
2025-07-15 18:33:34.812 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:34.812 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.338 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.ContinentPersistenceJpaAdapterTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.CountryPersistenceJpaAdapterTest
2025-07-15 18:33:35.154 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Node 1 disconnected.
2025-07-15 18:33:35.154 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-geojson-processor-20, groupId=geojson-processor] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
2025-07-15 18:33:35.340 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Node 1 disconnected.
2025-07-15 18:33:35.340 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-22, groupId=elasticsearch-deleter] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.378 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.CountryPersistenceJpaAdapterTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.DistrictPersistenceJpaAdapterTest
2025-07-15 18:33:35.685 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Node 1 disconnected.
2025-07-15 18:33:35.685 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-indexer-21, groupId=elasticsearch-indexer] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.301 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.DistrictPersistenceJpaAdapterTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.ProvincePersistenceJpaAdapterTest
2025-07-15 18:33:35.866 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Node 1 disconnected.
2025-07-15 18:33:35.866 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] o.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-elasticsearch-deleter-all-19, groupId=elasticsearch-deleter-all] Connection to node 1 (localhost/127.0.0.1:34713) could not be established. Node may not be available.
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.196 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.ProvincePersistenceJpaAdapterTest
[INFO] Running de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.RegionPersistenceJpaAdapterTest
[INFO] Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.072 s -- in de.org.dexterity.bookanything.dom01geolocation.infrastructure.adapters.output.persistence.jpa.adapters.RegionPersistenceJpaAdapterTest
[INFO] 
[INFO] Results:
[INFO] 
[ERROR] Errors: 
[ERROR]   LocalizablePlaceDeletionIntegrationTest.shouldDeleteAllLocalizablePlaces:72 » ConditionTimeout Assertion condition defined as a Lambda expression in de.org.dexterity.bookanything.dom01geolocation.LocalizablePlaceDeletionIntegrationTest expected: <10> but was: <0> within 30 seconds.
[INFO] 
[ERROR] Tests run: 78, Failures: 0, Errors: 1, Skipped: 0
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  09:33 min
[INFO] Finished at: 2025-07-15T18:33:36+02:00
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.5.3:test (default-test) on project bookanything-monolith-backend-01: 
[ERROR] 
[ERROR] See /home/andre.nascimento/DevEnvALNS/projects/03-PoCs-And-Researches/ALNS-RemoteGitRepos/GitHub-scout23DF/bookanything-platform/1-backends/bookanything-monolith-backend-01/target/surefire-reports for the individual test results.
[ERROR] See dump files (if any exist) [date].dump, [date]-jvmRun[N].dump and [date].dumpstream.
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
